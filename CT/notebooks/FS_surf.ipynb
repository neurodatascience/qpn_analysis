{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to visualize FreeSurfer measaures on surfaces and parcellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainspace.datasets import load_group_fc, load_parcellation, load_conte69\n",
    "from brainspace.plotting import plot_hemispheres\n",
    "from brainspace.mesh.mesh_io import read_surface\n",
    "from nibabel.freesurfer.mghformat import load\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import datasets, surface, plotting\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "current_release = \"Oct_2024\"\n",
    "FS_version = \"7.3.2\" #\"6.0.1\" #\"7.3.2\"\n",
    "session = \"ses-01\"\n",
    "dataset = \"qpn\"\n",
    "\n",
    "\n",
    "dataset_dir = f\"/home/nikhil/projects/Parkinsons/{dataset}/\"\n",
    "release_dir = f\"{dataset_dir}/releases/{current_release}/\"\n",
    "tabular_dir = f\"{release_dir}/tabular/\"\n",
    "\n",
    "# Current nipoppy manifest\n",
    "manifest_csv = f\"{release_dir}/manifest.csv\"\n",
    "\n",
    "# demographics\n",
    "demographics_csv = f\"{tabular_dir}/demographics.csv\"\n",
    "\n",
    "# Dx\n",
    "dx_csv = f\"{tabular_dir}/assessments/diagnosis.csv\"\n",
    "\n",
    "# imaging derivatives\n",
    "FS_dir = f\"{dataset_dir}/derivatives/freesurfer/v{FS_version}\"\n",
    "surf_dir = f\"{FS_dir}/surfmaps/{session}/\"\n",
    "\n",
    "# ROI stats\n",
    "DKT_csv = \"/home/nikhil/projects/Parkinsons/neuro_arch/analysis/IDP/qpn/Aug_2024/agg_dfs/CT_DKT_df.csv\"\n",
    "\n",
    "# Surface maps\n",
    "FS_surf_dir = f\"{FS_dir}/surfmaps/{session}/\"\n",
    "\n",
    "# Results\n",
    "figs_dir = f\"{dataset_dir}/results/{session}/anat/figs/\"\n",
    "Path(f\"{figs_dir}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get analysis groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_df = pd.read_csv(dx_csv)\n",
    "dx_df = dx_df[dx_df[\"redcap_event_name\"] == \"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "control_participants = dx_df[dx_df[\"diagnosis_group_for_analysis\"] == \"control\"][\"participant_id\"].unique()\n",
    "PD_participants = dx_df[dx_df[\"diagnosis_group_for_analysis\"] == \"PD\"][\"participant_id\"].unique()\n",
    "\n",
    "print(f\"Control: {len(control_participants)}\")\n",
    "print(f\"PD: {len(PD_participants)}\")\n",
    "\n",
    "dx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot CT on surface\n",
    "- e.g. lh_surf_concat_thickness_10mm.mgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_FS_surf(FS_surf_dir,participant_id, meas=\"thickness\", fwhm=10):\n",
    "    \"\"\" Read freesurfer surfaces for a given participant and hemisphere \"\"\"\n",
    "    # sub-MNI0143_lh_surf_thickness_10mm.mgh\n",
    "\n",
    "    surf_data = {}\n",
    "    try:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            surf_file = f\"{FS_surf_dir}/sub-{participant_id}_{hemi}_surf_{meas}_{fwhm}mm.mgh\"\n",
    "            surf_data[hemi] = nib.load(surf_file).get_fdata()\n",
    "            surf_sum = np.sum(surf_data[hemi].flatten())\n",
    "\n",
    "            # check if the surface is empty\n",
    "            if surf_sum == 0:\n",
    "                print(f\"Empty surface for {participant_id} {hemi}\")\n",
    "                return None            \n",
    "                    \n",
    "        return surf_data\n",
    "    \n",
    "    except:\n",
    "        print(f\"Error reading {participant_id}\")\n",
    "        return None    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PD_surf_data_lh = []\n",
    "PD_surf_data_rh = []\n",
    "control_surf_data_lh = []\n",
    "control_surf_data_rh = []\n",
    "\n",
    "for participant_id in control_participants:\n",
    "    surf_data = read_FS_surf(FS_surf_dir,participant_id)\n",
    "    if surf_data is not None:    \n",
    "        control_surf_data_lh.append(surf_data[\"lh\"]) \n",
    "        control_surf_data_rh.append(surf_data[\"rh\"]) \n",
    "\n",
    "for participant_id in PD_participants:\n",
    "    surf_data = read_FS_surf(FS_surf_dir, participant_id)\n",
    "    if surf_data is not None:\n",
    "        PD_surf_data_lh.append(surf_data[\"lh\"])\n",
    "        PD_surf_data_rh.append(surf_data[\"rh\"])\n",
    "\n",
    "# Global averages for sanity checks\n",
    "control_surf_lh_avg = np.mean(np.squeeze(control_surf_data_lh), axis=1)\n",
    "control_surf_rh_avg = np.mean(np.squeeze(control_surf_data_rh), axis=1)\n",
    "\n",
    "PD_surf_lh_avg = np.mean(np.squeeze(PD_surf_data_lh), axis=1)\n",
    "PD_surf_rh_avg = np.mean(np.squeeze(PD_surf_data_rh), axis=1)\n",
    "\n",
    "print(f\"control_surf_lh_min_max: {np.min(control_surf_lh_avg)}, {np.max(control_surf_lh_avg)}\")\n",
    "print(f\"control_surf_rh_min_max: {np.min(control_surf_rh_avg)}, {np.max(control_surf_rh_avg)}\")\n",
    "\n",
    "print(f\"PD_surf_lh_min_max: {np.min(PD_surf_lh_avg)}, {np.max(PD_surf_lh_avg)}\")\n",
    "print(f\"PD_surf_rh_min_max: {np.min(PD_surf_rh_avg)}, {np.max(PD_surf_rh_avg)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(control_surf_lh_avg.flatten(), color=\"blue\", alpha=0.5)\n",
    "sns.histplot(PD_surf_lh_avg.flatten(), color=\"green\", alpha=0.5)\n",
    "sns.histplot(control_surf_rh_avg.flatten(), color=\"red\", alpha=0.5)\n",
    "sns.histplot(PD_surf_rh_avg.flatten(), color=\"pink\", alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_surface = \"fsaverage\" # \"fsaverage\" or \"fsaverage5\"\n",
    "\n",
    "if template_surface == \"fsaverage\":\n",
    "    fsaverage_dir = f\"{FS_dir}/output/ses-01/fsaverage/\"\n",
    "    annot_dir = f\"{fsaverage_dir}/label/\"\n",
    "    \n",
    "else:\n",
    "    fsaverage_dir = \"/home/nikhil/projects/neuroinformatics_tools/micapipe/surfaces/fsaverage5/\"\n",
    "    annot_dir = \"/home/nikhil/projects/neuroinformatics_tools/micapipe/parcellations/\"\n",
    "\n",
    "surf_dir = f\"{fsaverage_dir}/surf/\"\n",
    "\n",
    "pial_lh = read_surface(f\"{surf_dir}/lh.pial\", itype='fs')\n",
    "pial_rh = read_surface(f\"{surf_dir}/rh.pial\", itype='fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "\n",
    "# average across groups (axis = 0)\n",
    "PD_surf_lh_avg = np.mean(np.squeeze(PD_surf_data_lh), axis=0)\n",
    "PD_surf_rh_avg = np.mean(np.squeeze(PD_surf_data_rh), axis=0)\n",
    "\n",
    "PD_surf_avg = [np.expand_dims(PD_surf_lh_avg, axis=(1)), np.expand_dims(PD_surf_rh_avg,axis=(1))]\n",
    "PD_surf_avg = np.squeeze(np.concatenate(PD_surf_avg, axis=0))\n",
    "\n",
    "if save_fig:\n",
    "    save_file = f\"{figs_dir}/CT_surf_PD.png\"\n",
    "else:\n",
    "    save_file = None\n",
    "\n",
    "# Plot the surfaces\n",
    "plot_hemispheres( pial_lh, pial_rh, array_name=PD_surf_avg, size=(900, 250), color_bar='bottom', zoom=1.25, embed_nb=True, \n",
    "                 interactive=True, share='both',layout_style=\"compact\", #filename=save_file,\n",
    "                 nan_color=(255, 255, 255, 1), color_range=(1.5, 3), cmap=\"inferno\", transparent_bg=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "\n",
    "# average across groups (axis = 0)\n",
    "control_surf_lh_avg = np.mean(np.squeeze(control_surf_data_lh), axis=0)\n",
    "control_surf_rh_avg = np.mean(np.squeeze(control_surf_data_rh), axis=0)\n",
    "\n",
    "control_surf_avg = [np.expand_dims(control_surf_lh_avg, axis=(1)), np.expand_dims(control_surf_rh_avg,axis=(1))]\n",
    "control_surf_avg = np.squeeze(np.concatenate(control_surf_avg, axis=0))\n",
    "\n",
    "if save_fig:\n",
    "    save_file = f\"{figs_dir}/CT_surf_control.png\"\n",
    "else:\n",
    "    save_file = None\n",
    "\n",
    "# Plot the surfaces\n",
    "plot_hemispheres( pial_lh, pial_rh, array_name=control_surf_avg, size=(900, 250), color_bar='bottom', zoom=1.25, embed_nb=True, \n",
    "                 interactive=True, share='both',layout_style=\"compact\", #filename=save_file,\n",
    "                 nan_color=(255, 255, 255, 1), color_range=(1.5, 3), cmap=\"inferno\", transparent_bg=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between CTRL and PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PD_minus_control_surf_avg = PD_surf_avg - control_surf_avg\n",
    "\n",
    "# Plot the surfaces\n",
    "plot_hemispheres( pial_lh, pial_rh, array_name=PD_minus_control_surf_avg, size=(900, 250), color_bar='bottom', zoom=1.25, embed_nb=True, \n",
    "                 interactive=True, share='both',layout_style=\"compact\",\n",
    "                 nan_color=(255, 255, 255, 1), color_range=(-.2,.1), cmap=\"inferno\", transparent_bg=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot labels on the surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot labels on surface\n",
    "plot_hemispheres(pial_lh, pial_rh, array_name=labels, size=(900, 250), zoom=1.25, embed_nb=True, interactive=False, share='both',\n",
    "                 nan_color=(0, 0, 0, 1), cmap='nipy_spectral', transparent_bg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot average CT per parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_CT_per_parcel(labels, CT_vals, round_decimals=1):\n",
    "\n",
    "    CT_parcel_df = pd.DataFrame()\n",
    "    CT_parcel_df[\"CT\"] = CT_vals\n",
    "    CT_parcel_df[\"label\"] = labels\n",
    "    mean_CT_per_label_df = CT_parcel_df.groupby(\"label\").mean().reset_index()\n",
    "    label_CT_map_dict = dict(zip(mean_CT_per_label_df[\"label\"], mean_CT_per_label_df[\"CT\"]))\n",
    "    CT_parcel_df[\"CT_parcel\"] = CT_parcel_df[\"label\"].replace(label_CT_map_dict)\n",
    "    mean_CT_parcel = np.array(CT_parcel_df[\"CT_parcel\"],dtype=np.float32).round(round_decimals)\n",
    "\n",
    "    return mean_CT_parcel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean CT per parcel on surface\n",
    "plot_array = get_mean_CT_per_parcel(labels, CTRL_surf)\n",
    "cmap = \"inferno\"\n",
    "plot_hemispheres(pial_lh, pial_rh, array_name=plot_array, size=(900, 250), zoom=1.25, embed_nb=True, interactive=False, share='both',\n",
    "                 nan_color=(0, 0, 0, 1), cmap=cmap, transparent_bg=True,color_bar='bottom') #color_range=(1.5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean CT per parcel on surface\n",
    "plot_array = get_mean_CT_per_parcel(labels, PD_surf)\n",
    "cmap = \"inferno\"\n",
    "plot_hemispheres(pial_lh, pial_rh, array_name=plot_array, size=(900, 250), zoom=1.25, embed_nb=True, interactive=False, share='both',\n",
    "                 nan_color=(0, 0, 0, 1), cmap=cmap, transparent_bg=True, color_bar='bottom') #color_range=(1.5, 4),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between CTRL and PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean CT per parcel on surface\n",
    "plot_thresh = 0.05\n",
    "diff_surf = surf_dict[\"CTRL\"] - surf_dict[\"PD\"]\n",
    "diff_surf[(diff_surf < plot_thresh) & (diff_surf > -plot_thresh)] = 0\n",
    "\n",
    "plot_array = get_mean_CT_per_parcel(labels, diff_surf, round_decimals=2)\n",
    "color_range = (-max(abs(plot_array)), max(abs(plot_array)))\n",
    "cmap = \"coolwarm\"\n",
    "plot_hemispheres(pial_lh, pial_rh, array_name=plot_array, size=(900, 250), zoom=1.25, embed_nb=True, interactive=False, share='both',\n",
    "                 nan_color=(0, 0, 0, 1), cmap=cmap, transparent_bg=True, color_bar='bottom',color_range=color_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempts to plot DKT parcels from aparc summaries..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface and annotation files\n",
    "\n",
    "- Possible surfaces: [\"fsaverage\", \"fsaverage5\"]\n",
    "- Possible annot: \n",
    "    - \"fsaverage\": [\"aparc\", \"aparc.a2009s\", \"Yeo2011_7Networks_N1000\", \"Yeo2011_17Networks_N1000\"]\n",
    "    - \"fsaverage5\": [\"schaefer-500\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_surface = \"fsaverage\" # \"fsaverage\" or \"fsaverage5\"\n",
    "annot = \"aparc\" #\"Yeo2011_7Networks_N1000\"\n",
    "\n",
    "if template_surface == \"fsaverage\":\n",
    "    fsaverage_dir = f\"{FS_dir}/output/ses-01/fsaverage/\"\n",
    "    annot_dir = f\"{fsaverage_dir}/label/\"\n",
    "    \n",
    "else:\n",
    "    fsaverage_dir = \"/home/nikhil/projects/neuroinformatics_tools/micapipe/surfaces/fsaverage5/\"\n",
    "    annot_dir = \"/home/nikhil/projects/neuroinformatics_tools/micapipe/parcellations/\"\n",
    "\n",
    "surf_dir = f\"{fsaverage_dir}/surf/\"\n",
    "\n",
    "pial_lh = read_surface(f\"{surf_dir}/lh.pial\", itype='fs')\n",
    "pial_rh = read_surface(f\"{surf_dir}/rh.pial\", itype='fs')\n",
    "\n",
    "\n",
    "if annot in [\"aparc\", \"aparc.a2009s\", \"Yeo2011_7Networks_N1000\", \"Yeo2011_17Networks_N1000\"]:\n",
    "    annot_lh= f\"{annot_dir}/lh.{annot}.annot\"\n",
    "    annot_rh= f\"{annot_dir}/rh.{annot}.annot\"\n",
    "else:\n",
    "    annot_lh= f\"{annot_dir}/lh.{annot}_mics.annot\"\n",
    "    annot_rh= f\"{annot_dir}/rh.{annot}_mics.annot\"\n",
    "\n",
    "labels = np.concatenate((nib.freesurfer.read_annot(annot_lh)[0], nib.freesurfer.read_annot(annot_rh)[0]), axis=0)\n",
    "\n",
    "print(f\"tempate surface: {template_surface}, annot: {annot}\")\n",
    "print(f\"shape of concat array: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare fsaverage and subject space labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_info(annot_file):\n",
    "    annot = nib.freesurfer.read_annot(annot_file)\n",
    "    labels = annot[0]\n",
    "    n_vertices = len(labels)\n",
    "    label_idx = np.unique(labels)\n",
    "    label_names = annot[2]\n",
    "    \n",
    "    return n_vertices, label_idx, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsaverage_label_dir = f\"{FS_dir}/output/ses-01/fsaverage/label/\"\n",
    "subject_label_dir = f\"{FS_dir}/output/ses-01/sub-MNI0028/label/\"\n",
    "\n",
    "# Load the annotation file\n",
    "parcel = \"aparc\"\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    fsaverage_annot_file = f\"{fsaverage_label_dir}/{hemi}.{parcel}.annot\"\n",
    "    subject_annot_file = f\"{subject_label_dir}/{hemi}.{parcel}.annot\"\n",
    "\n",
    "    print(f\"{hemi} {parcel}\")\n",
    "    n_vertices, fsaverage_label_idx, fsaverage_label_names = get_label_info(fsaverage_annot_file)\n",
    "    print(f\"Number of vertices: {n_vertices}, n_idx: {len(fsaverage_label_idx)}, n_names: {len(fsaverage_label_names)}\")\n",
    "    \n",
    "    n_vertices, subject_label_idx, subject_label_names = get_label_info(subject_annot_file)\n",
    "    print(f\"Number of vertices: {n_vertices}, n_idx: {len(subject_label_idx)}, n_names: {len(subject_label_names)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot DKT values on brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_CT_labels_df(ct_df, group, hemi, annot_file, ct_cols):\n",
    "    \"\"\"\n",
    "    Get mean CT values for each ROI per hemi per group\n",
    "    \"\"\"\n",
    "    ct_labels_df = pd.DataFrame()\n",
    "\n",
    "    mean_ct = ct_df[(ct_df[\"enrollment_group\"]==group) & (ct_dkt_df[\"hemi\"]==hemi)][ct_cols].mean(axis=0)    \n",
    "    mean_ct_df = pd.DataFrame(mean_ct, columns=[\"mean_CT\"]).reset_index().rename(columns={\"index\": \"ROI\"})\n",
    "    \n",
    "    # grab ROIs\n",
    "    fs_annot = nib.freesurfer.read_annot(annot_file)\n",
    "    ROIs = fs_annot[2]\n",
    "    ROIs = [r.decode(\"utf-8\") for r in ROIs] \n",
    "    n_ROIs = len(ROIs)\n",
    "    print(f\"Number of ROIs: {n_ROIs}\")\n",
    "    ROIs_df = pd.DataFrame(ROIs, columns=[\"ROI\"])\n",
    "    ROIs_df[\"ROI_index\"] = np.arange(n_ROIs)\n",
    "\n",
    "    # merge CT values with ROI names and index\n",
    "    mean_ct_df = mean_ct_df.merge(ROIs_df, on=\"ROI\")\n",
    "\n",
    "    # ROI_index --> CT_val dict\n",
    "    ROI_index_CT_dict = mean_ct_df.set_index(\"ROI_index\")[\"mean_CT\"].to_dict()\n",
    "\n",
    "    # grab vertex wise labels\n",
    "    labels = fs_annot[0]\n",
    "    labels_df = pd.DataFrame(labels, columns=[\"ROI_index\"])\n",
    "    \n",
    "    CT_df = pd.DataFrame(labels, columns=[\"ROI_index\"])\n",
    "    CT_df[\"mean_CT\"] = CT_df[\"ROI_index\"].map(ROI_index_CT_dict)\n",
    "\n",
    "    return CT_df, mean_ct_df, ROI_index_CT_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dkt_df = pd.read_csv(DKT_csv)\n",
    "\n",
    "demo_cols = [\"participant_id\", \"sex\", \"enrollment_group\", \"hemi\"]\n",
    "ct_cols = list(set(ct_dkt_df.columns) - set(demo_cols))\n",
    "\n",
    "group = \"control\"\n",
    "\n",
    "lh_CT_df, _, _ = get_mean_CT_labels_df(ct_dkt_df, group, \"lh\", annot_lh, ct_cols)\n",
    "rh_CT_df, _, _ = get_mean_CT_labels_df(ct_dkt_df, group, \"rh\", annot_rh, ct_cols)\n",
    "\n",
    "CT_df = pd.concat([lh_CT_df, rh_CT_df], axis=0)\n",
    "CT_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot labels on surface\n",
    "print(\"plotting CT values\")\n",
    "plot_array = CT_df[\"mean_CT\"].values\n",
    "plot_hemispheres(pial_lh, pial_rh, array_name=plot_array, size=(900, 250), zoom=1.25, embed_nb=True, interactive=False, share='both',\n",
    "                 nan_color=(0, 0, 0, 1), cmap='BuPu', transparent_bg=True, color_bar='bottom', layout_style=\"compact\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
