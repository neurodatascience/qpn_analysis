{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to report descriptive statistics from demoraphic and assessment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/nikhil/projects/Parkinsons/qpn/\"\n",
    "\n",
    "# Current nipoppy release\n",
    "current_release = \"June_2024\"\n",
    "\n",
    "data_release_dir = f\"{DATASET_ROOT}/releases/{current_release}/\"\n",
    "tabular_data_release_dir = f\"{data_release_dir}/tabular/\"\n",
    "manifest_file = f\"{data_release_dir}/manifest.csv\"\n",
    "\n",
    "# tabular files\n",
    "demographics_file = f\"{tabular_data_release_dir}/demographics.csv\"\n",
    "mri_session_date_file = f\"{tabular_data_release_dir}/mri_sessions.csv\"\n",
    "updrs_file = f\"{tabular_data_release_dir}/assessments/updrs.csv\"\n",
    "moca_file = f\"{tabular_data_release_dir}/assessments/moca.csv\"\n",
    "dx_file = f\"{tabular_data_release_dir}/assessments/diagnosis.csv\"\n",
    "neuropsych_file = f\"{tabular_data_release_dir}/assessments/neuropsych.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_and_replace_df(df, filters_dict, rename_dict):\n",
    "    \"\"\" Subset rows and replace columns values in a dataframe\n",
    "    \"\"\"\n",
    "    for col, val_list in filters_dict.items():\n",
    "        df = df[df[col].isin(val_list)].copy()\n",
    "\n",
    "    for col, val_list in rename_dict.items():\n",
    "        df[col] = df[col].replace(val_list).copy()\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "def get_group_table_stats(df, cat_cols, score_cols, groupby_col=\"redcap_event_name\"):\n",
    "    \"\"\" Get table stats for groups. Does not stratify by group! \n",
    "    \"\"\"\n",
    "    n_cat_cols = len(cat_cols)\n",
    "    n_score_cols = len(score_cols)\n",
    "    print(f\"Counting {n_cat_cols} and averaging {n_score_cols}\")\n",
    "\n",
    "    table_df = df[\"redcap_event_name\"].value_counts().reset_index()\n",
    "    print(\"Starting cat cols\")\n",
    "    for col in cat_cols:\n",
    "        # print(f\"col: {col}\")\n",
    "        cat_count_df = df.groupby([groupby_col])[col].value_counts().unstack().reset_index()\n",
    "        table_df = pd.merge(table_df, cat_count_df, on=groupby_col, how=\"left\")\n",
    "\n",
    "    print(\"Starting score cols\")\n",
    "    for col in score_cols:\n",
    "        # print(f\"col: {col}\")\n",
    "        score_count = df.groupby([groupby_col])[col].count()\n",
    "        score_mean_df = df.groupby([groupby_col])[col].mean().round(1)\n",
    "        score_std_df = df.groupby([groupby_col])[col].std().round(1)\n",
    "        score_min_df = df.groupby([groupby_col])[col].min().round(1)\n",
    "        score_max_df = df.groupby([groupby_col])[col].max().round(1)\n",
    "        score_mean_std_df = \"non-null-count: \" + score_count.astype(str) + \" \" + score_mean_df.astype(str) + \" (\" + score_std_df.astype(str) + \")\" + \" [\"  \\\n",
    "        + score_min_df.astype(str) + \", \" + score_max_df.astype(str) + \"]\"\n",
    "        score_mean_std_df = score_mean_std_df.reset_index()\n",
    "        # score_mean_std_df[\"non-null-count\"] = score_count\n",
    "        table_df = pd.merge(table_df, score_mean_std_df, on=groupby_col, how=\"left\")\n",
    "    \n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_df = pd.read_csv(manifest_file)\n",
    "demo_df = pd.read_csv(demographics_file)\n",
    "mri_df = pd.read_csv(mri_session_date_file)\n",
    "updrs_df = pd.read_csv(updrs_file)\n",
    "moca_df = pd.read_csv(moca_file)\n",
    "dx_df = pd.read_csv(dx_file)\n",
    "neuropsy_df = pd.read_csv(neuropsych_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QPN paper tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper subset filters\n",
    "cohort_inclusion_list = [\"QPN\"]\n",
    "group_inclusion_list = [\"Healthy control/Contrôle\", \"PD   (Parkinson's Disease)/Maladie de Parkinson\"]\n",
    "visits_inclusion_list = [\"Baseline (Arm 1: C-OPN)\", \"pre-redcap-baseline-1 (legacy)\", \"pre-redcap-baseline-2 (legacy)\",\n",
    "                         \"12 Months Follow-Up/Suivi (Arm 1: C-OPN)\",\"18 Months Follow-Up/Suivi (Arm 1: C-OPN)\"]\n",
    "\n",
    "participant_inclusion_criteria = {\n",
    "    \"redcap_event_name\" : visits_inclusion_list, \n",
    "    \"recruitment_cohort\": cohort_inclusion_list,\n",
    "    \"group\": group_inclusion_list\n",
    "    }\n",
    "\n",
    "QPN_groups = {\"Healthy control/Contrôle\": \"control\", \"PD   (Parkinson's Disease)/Maladie de Parkinson\": \"PD\", np.NaN:\"Unknown\"}\n",
    "QPN_sexes = {\"Female/Féminin\": \"Female\", \"Male/Masculin\":\"Male\"}\n",
    "\n",
    "col_val_replacement_criteria = {\n",
    "    \"group\": QPN_groups,\n",
    "    \"sex\": QPN_sexes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df = pd.merge(manifest_df, demo_df, on=\"participant_id\", how=\"left\")\n",
    "paper_df = paper_df[paper_df[\"recruitment_cohort\"]==\"QPN\"]\n",
    "\n",
    "n_tabular_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants: {n_tabular_participants}\")\n",
    "\n",
    "# Filter and replace values\n",
    "paper_df = subset_and_replace_df(paper_df, participant_inclusion_criteria, col_val_replacement_criteria)\n",
    "n_paper_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants after event and group filter: {n_paper_participants}\")\n",
    "\n",
    "session_counts = paper_df[\"session\"].value_counts()\n",
    "print(f\"session_counts: {session_counts}\")\n",
    "\n",
    "paper_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo table\n",
    "- Add MRI age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mri_age column\n",
    "paper_df = pd.merge(demo_df, mri_df[[\"participant_id\", \"redcap_event_name\", \"MRI_age\"]], on=[\"participant_id\", \"redcap_event_name\"], how=\"left\")\n",
    "\n",
    "n_tabular_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants: {n_tabular_participants}\")\n",
    "\n",
    "# Filter and replace values\n",
    "paper_df = subset_and_replace_df(paper_df, participant_inclusion_criteria, col_val_replacement_criteria)\n",
    "n_paper_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants after event and group filter: {n_paper_participants}\")\n",
    "\n",
    "redcap_events = paper_df[\"redcap_event_name\"].unique()\n",
    "print(f\"redcap events: {redcap_events}\")\n",
    "\n",
    "paper_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts\n",
    "cat_cols = [\"sex\"]\n",
    "score_cols = [\"MRI_age\"]\n",
    "\n",
    "for dx_group in QPN_groups.values():\n",
    "    print(f\"*** group: {dx_group} ***\")\n",
    "    dx_group_df = paper_df[paper_df[\"group\"]==dx_group].copy()\n",
    "    table_df = get_group_table_stats(dx_group_df, cat_cols, score_cols)\n",
    "    print(\"-\"*10)\n",
    "    print(table_df)\n",
    "    print(\"-\"*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPDRS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df = pd.merge(demo_df.drop(columns=[\"redcap_event_name\"]), updrs_df, on=[\"participant_id\"], how=\"right\")\n",
    "paper_df = pd.merge(paper_df, dx_df, on=[\"participant_id\",\"redcap_event_name\"], how=\"left\")\n",
    "\n",
    "n_tabular_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants: {n_tabular_participants}\")\n",
    "\n",
    "# Filter and replace values\n",
    "paper_df = subset_and_replace_df(paper_df, participant_inclusion_criteria, col_val_replacement_criteria)\n",
    "n_paper_mds_updrs_participants = paper_df[~paper_df[\"Part III: Motor Examination\"].isna()][\"redcap_event_name\"].value_counts()\n",
    "n_paper_legacy_updrs_participants = paper_df[~paper_df[\"legacy_updrs3_scores\"].isna()][\"participant_id\"].nunique()\n",
    "print(f\"Number of mds-updrs participants after event and group filter: {n_paper_mds_updrs_participants}\")\n",
    "print(f\"Number of legacy-updrs participants after event and group filter: {n_paper_legacy_updrs_participants}\")\n",
    "\n",
    "# find common participants between 12 and 18 month visits\n",
    "participants_12m = paper_df[paper_df[\"redcap_event_name\"] == \"12 Months Follow-Up/Suivi (Arm 1: C-OPN)\"][\"participant_id\"]\n",
    "participants_18m = paper_df[paper_df[\"redcap_event_name\"] == \"18 Months Follow-Up/Suivi (Arm 1: C-OPN)\"][\"participant_id\"]\n",
    "participants_union = set(participants_12m) | set(participants_18m)\n",
    "participants_intersection = set(participants_12m) & set(participants_18m)\n",
    "\n",
    "print(f\"participants_union: {len(participants_union)}\")\n",
    "print(f\"participants_intersection: {len(participants_intersection)}\")\n",
    "\n",
    "paper_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot phono data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class my_colors(Enum):\n",
    "    CONTROL = \"#8d99ae\"\n",
    "    PD = \"#e63946\"\n",
    "    \n",
    "color_list = [my_colors.PD.value, my_colors.CONTROL.value,]\n",
    "palette = sns.color_palette(palette=color_list) #sns.husl_palette()\n",
    "\n",
    "monocrome_hot = [\"#370617\",\"#6a040f\",\"#9d0208\",\"#d00000\",\"#dc2f02\",\"#e85d04\",\"#f48c06\",\"#faa307\",\"#ffba08\"]\n",
    "monochrome_hot_palette = sns.color_palette(palette=monocrome_hot[::-2]) #sns.husl_palette()\n",
    "\n",
    "sns.palplot(monochrome_hot_palette)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updrs_cols_dict = {\n",
    "    \"Hoehn and Yahr Stage: \":'H_Y_stage',\n",
    "    'Part I: Non-Motor Aspects of Experiences of Daily Living (nM-EDL)':'Part I',\n",
    "    'Part II: Motor Aspects of Experiences of Daily Living (M-EDL)':'Part II',\n",
    "    'Part III: Motor Examination':'Part III',\n",
    "    'Part IV: Motor Complications':'Part IV',\n",
    "}\n",
    "\n",
    "H_Y_stage_dict = dict(zip(\n",
    "    [\n",
    "    '(2) Bilateral involvement without impairment of balance',\n",
    "    '(3) Bilateral disease: mild to moderate disability with impaired postural reflexes; physically independent; needs assistance to recover from pull test',\n",
    "    '(1) Unilateral involvement only, usually with minimal or no functional disability',\n",
    "    '(0) Asymptomatic',\n",
    "    '(4) Severely disabling disease; still able to walk or stand unassisted',\n",
    "    np.nan], \n",
    "    \n",
    "    ['2', '3', '1', '0', '4', \"N/A\"]\n",
    "))\n",
    "\n",
    "paper_df = paper_df.rename(columns=updrs_cols_dict)\n",
    "paper_df[\"H_Y_stage\"] = paper_df[\"H_Y_stage\"].replace(H_Y_stage_dict)\n",
    "paper_df = paper_df[paper_df[\"H_Y_stage\"]!=\"N/A\"]\n",
    "\n",
    "# Melt for plotting\n",
    "plot_df = pd.melt(paper_df, id_vars=[\"participant_id\",\"redcap_event_name\",\"group\",\"H_Y_stage\"], \n",
    "                  value_vars=['Part I', 'Part II', 'Part III', 'Part IV'], \n",
    "                  var_name=\"UPDRS\", value_name=\"Score\")\n",
    "\n",
    "plot_df = plot_df[plot_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "stage_order = ['0', '1', '2', '3', '4']\n",
    "\n",
    "sns.set_theme(font_scale=2)\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(y=\"Score\",x=\"H_Y_stage\", order=stage_order,\n",
    "                    col=\"UPDRS\", col_wrap=2, \n",
    "                    kind=\"box\", palette=monochrome_hot_palette, \n",
    "                    data=plot_df, aspect=2, height=5, sharey=False)\n",
    "    # g.set_xlabels(\"\")\n",
    "    # g.set_xticklabels(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df[\"group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"H_Y_stage\"]\n",
    "score_cols = [\"Part I\", \"Part II\", \"Part III\", \"Part IV\"]\n",
    "\n",
    "# paper_df = paper_df[paper_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "for dx_group in [\"PD\", \"control\"]:\n",
    "    print(f\"*** group: {dx_group} ***\")\n",
    "    dx_group_df = paper_df[paper_df[\"group\"]==dx_group].copy()\n",
    "    table_df = get_group_table_stats(dx_group_df, cat_cols, score_cols)\n",
    "    print(\"-\"*10)\n",
    "    print(table_df)\n",
    "    print(\"-\"*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legacy score stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updrs_df[\"legacy_updrs3_scores\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"H_Y_stage\"]\n",
    "score_cols = [\"legacy_updrs3_scores\"]\n",
    "\n",
    "# paper_df = paper_df[paper_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "for dx_group in [\"PD\", \"control\"]:\n",
    "    print(f\"*** group: {dx_group} ***\")\n",
    "    dx_group_df = paper_df[paper_df[\"group\"]==dx_group].copy()\n",
    "    table_df = get_group_table_stats(dx_group_df, cat_cols, score_cols)\n",
    "    print(\"-\"*10)\n",
    "    print(table_df)\n",
    "    print(\"-\"*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MoCA score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df = pd.merge(demo_df.drop(columns=[\"redcap_event_name\"]), moca_df, on=[\"participant_id\"], how=\"right\")\n",
    "paper_df = pd.merge(paper_df, dx_df, on=[\"participant_id\",\"redcap_event_name\"], how=\"left\")\n",
    "\n",
    "n_tabular_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants: {n_tabular_participants}\")\n",
    "\n",
    "# Filter and replace values\n",
    "paper_df = subset_and_replace_df(paper_df, participant_inclusion_criteria, col_val_replacement_criteria)\n",
    "n_paper_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants after event and group filter: {n_paper_participants}\")\n",
    "\n",
    "redcap_event_counts = paper_df[\"redcap_event_name\"].value_counts()\n",
    "print(f\"redcap_event_counts: {redcap_event_counts}\")\n",
    "\n",
    "# find common participants between redcap baseline and legacy baseline\n",
    "participants_redcap_baseline = paper_df[paper_df[\"redcap_event_name\"] == \"Baseline (Arm 1: C-OPN)\"][\"participant_id\"]\n",
    "participants_legacy_baseline = paper_df[paper_df[\"redcap_event_name\"] == \"pre-redcap-baseline-1 (legacy)\"][\"participant_id\"]\n",
    "participants_union = set(participants_redcap_baseline) | set(participants_legacy_baseline)\n",
    "participants_intersection = set(participants_redcap_baseline) & set(participants_legacy_baseline)\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Common participants between redcap baseline and legacy baseline\")\n",
    "print(f\"participants_union: {len(participants_union)}\")\n",
    "print(f\"participants_intersection: {len(participants_intersection)}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# find common participants between 12 and 18 month visits\n",
    "participants_12m = paper_df[paper_df[\"redcap_event_name\"] == \"12 Months Follow-Up/Suivi (Arm 1: C-OPN)\"][\"participant_id\"]\n",
    "participants_18m = paper_df[paper_df[\"redcap_event_name\"] == \"18 Months Follow-Up/Suivi (Arm 1: C-OPN)\"][\"participant_id\"]\n",
    "participants_union = set(participants_12m) | set(participants_18m)\n",
    "participants_intersection = set(participants_12m) & set(participants_18m)\n",
    "\n",
    "print(\"Common participants between 12 and 18 month visits\")\n",
    "print(f\"participants_union: {len(participants_union)}\")\n",
    "print(f\"participants_intersection: {len(participants_intersection)}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# find participants with at least 1 follow-up visit including legacy baseline\n",
    "participants_legacy_followup = set(participants_redcap_baseline) & set(participants_legacy_baseline)\n",
    "participants_followup = participants_legacy_followup | set(participants_12m) | set(participants_18m)\n",
    "print(\"Participants with at least 1 follow-up visit including legacy baseline\")\n",
    "print(f\"participants_followup: {len(participants_followup)}\")\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot moca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df = paper_df.rename(columns={\"TOTAL SCORE (make sure to include extra point for 12 years or less of education):    SCORE TOTAL (assurez-vous d'inclure un point supplémentaire pour 12 ans ou moins d'éducation) : \" :\"moca_total\"})\n",
    "plot_df = paper_df[paper_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "sns.set_theme(font_scale=1.5)\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(y=\"moca_total\",x=\"group\",\n",
    "                    kind=\"box\", palette=palette, \n",
    "                    data=plot_df, aspect=1.5, height=5, sharey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"group\"]\n",
    "score_cols = [\"moca_total\"]\n",
    "\n",
    "# paper_df = paper_df[paper_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "for dx_group in [\"PD\", \"control\"]:\n",
    "    print(f\"*** group: {dx_group} ***\")\n",
    "    dx_group_df = paper_df[paper_df[\"group\"]==dx_group].copy()\n",
    "    table_df = get_group_table_stats(dx_group_df, cat_cols, score_cols)\n",
    "    print(\"-\"*10)\n",
    "    print(table_df)\n",
    "    print(\"-\"*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuropsy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df = pd.merge(demo_df.drop(columns=[\"redcap_event_name\"]), neuropsy_df, on=[\"participant_id\"], how=\"right\")\n",
    "n_tabular_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants: {n_tabular_participants}\")\n",
    "\n",
    "# Filter and replace values\n",
    "paper_df = subset_and_replace_df(paper_df, participant_inclusion_criteria, col_val_replacement_criteria)\n",
    "n_paper_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants after event and group filter: {n_paper_participants}\")\n",
    "\n",
    "redcap_events = paper_df[\"redcap_event_name\"].unique()\n",
    "print(f\"redcap events: {redcap_events}\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Scores with lowest attrition (sorted)\")\n",
    "raw_score_cols = list(paper_df.columns[paper_df.columns.str.contains(\"score\")]) + list(paper_df.columns[paper_df.columns.str.contains(\"aw\")])\n",
    "raw_scores_paper_df = paper_df[[\"participant_id\", \"redcap_event_name\"] + raw_score_cols].copy()\n",
    "raw_scores_paper_df[raw_scores_paper_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"].isna().sum().sort_values(ascending=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores_paper_df[raw_scores_paper_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"].isna().sum().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = [\"participant_id\", \"redcap_event_name\",\"group\"]\n",
    "cat_cols = []\n",
    "\n",
    "neuropsy_source = \"redcap\"\n",
    "\n",
    "# redcap data\n",
    "if neuropsy_source == \"redcap\":\n",
    "    score_cols = [                   \n",
    "                    \"Repetitions total 1,2,3 (Raw score)\",\n",
    "                    \"Digit Span Forward - total correct (Raw score) \",\n",
    "                    \"Digit span forward - longest correct serie (Raw score)\",\n",
    "                    \"Digit Span Backward - total correct (Raw score)\",\n",
    "                    \"Digit span backward - longest correct serie (Raw score)  \",    \n",
    "                    \"Command Clock raw (max 10)\",\n",
    "                    \"Copy Clock raw (max 10)\",\n",
    "                    \"STROOP GOLDEN : words, self-corrected errors (raw score)\",\n",
    "                    \"STROOP GOLDEN, words, uncorrected errors (raw score)\",\n",
    "                    \"STROOP GOLDEN : colors, self-corrected errors (raw scores)\",\n",
    "                    \"Stroop GOLDEN : ink, self-corrected errors (raw score)\",\n",
    "                    \"Stroop GOLDEN, ink, uncorrected errors (raw score)\",\n",
    "                    \"Letter Fluency Total (Raw score)\",                    \n",
    "                    \"Trail A raw score (time in sec.)\",\n",
    "                    \"Trial total 1,2,3 (Raw score)\",                            \n",
    "                    \"Trial 4 delayed (Raw score)\",                                   \n",
    "                    \"BNT sans indice (Raw score)\",                                   \n",
    "                    \"Letter Fluency F (Raw score)\",                                  \n",
    "                    \"Semantic Fluency Actions (Raw score)\",\n",
    "                    \"Letter Fluency S (Raw score)\",                         \n",
    "                    \"Semantic Fluency Animals (Raw score)\",\n",
    "                    \"Letter Fluency A (Raw score)\",                                   \n",
    "                    \"Trail B raw score (time in sec.)\",\n",
    "                    \"Trail B Errors raw score\",\n",
    "                    \"Brixton raw score\",\n",
    "                ]\n",
    "\n",
    "# BD_RPQ data\n",
    "if neuropsy_source == \"local\":\n",
    "    score_cols = [\n",
    "                    \"HVLT Trial total 1,2,3 (Raw score)\",\n",
    "                    \"Clock Command (Raw score)\",\n",
    "                    \"Clock Copy (Raw score)\",\n",
    "                    \"Semantic Fluency Total (Raw score)\",\n",
    "                    \"RCFT Copy (Raw score)\",\n",
    "                    \"Letter Fluency Total (Raw score)\",\n",
    "                    \"STROOP GOLDEN : words, self-corrected errors (raw score)\",\n",
    "                    \"STROOP GOLDEN : colors, self-corrected errors (raw scores)\",\n",
    "                    \"Stroop GOLDEN : ink, self-corrected errors (raw score)\",                \n",
    "                    ]\n",
    "\n",
    "neuropsy_vars = index_cols + cat_cols + score_cols\n",
    "paper_df = paper_df[neuropsy_vars]\n",
    "n_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "\n",
    "neuropsy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dx_group in [\"PD\", \"control\"]:\n",
    "    print(f\"*** group: {dx_group} ***\")\n",
    "    # dx_group_df = paper_df[(paper_df[\"group\"]==dx_group) & (paper_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\")].copy()\n",
    "    dx_group_df = paper_df[(paper_df[\"group\"]==dx_group) ].copy()\n",
    "    table_df = get_group_table_stats(dx_group_df, cat_cols, score_cols)\n",
    "    print(\"-\"*10)\n",
    "    print(table_df)\n",
    "    print(\"-\"*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipoppy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
