{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to report descriptive statistics from demoraphic and assessment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import ptitprince as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_config_f = Path('../local_config.json')\n",
    "if local_config_f.exists():\n",
    "    with open(local_config_f) as f:\n",
    "        local_config = json.load(f)\n",
    "else:\n",
    "    print(f'Specify a local_config.json with path to nipoppy DATASET_DIR')\n",
    "\n",
    "print('local_config:', local_config)\n",
    "\n",
    "\n",
    "dx_color_palette = local_config['plot_styles']['DX_COLOR_PALETTE']\n",
    "palette = [dx_color_palette[\"PD\"], dx_color_palette[\"control\"]]\n",
    "\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = local_config['DATASET_DIR']\n",
    "current_release = local_config['DATASET_RELEASE']\n",
    "\n",
    "session = \"ses-01\"\n",
    "\n",
    "# Current nipoppy manifest\n",
    "manifest_file = f\"{dataset_dir}/manifest.csv\"\n",
    "\n",
    "# tabular data\n",
    "tabular_dir = f\"{dataset_dir}/tabular/\"\n",
    "\n",
    "# tabular files\n",
    "demographics_file = f\"{tabular_dir}/demographics.csv\"\n",
    "mri_session_date_file = f\"{tabular_dir}/mri_info/mri_sessions.csv\"\n",
    "updrs_file = f\"{tabular_dir}/assessments/updrs.csv\"\n",
    "hy_file = f\"{tabular_dir}/assessments/hy.csv\"\n",
    "moca_file = f\"{tabular_dir}/assessments/moca.csv\"\n",
    "dx_file = f\"{tabular_dir}/assessments/diagnosis.csv\"\n",
    "\n",
    "# neuropsych battery\n",
    "neuropsy_instruments_file = \"./neuropsy_instruments.csv\"\n",
    "neuropsy_scores_file = f\"{tabular_dir}/assessments/neuropsych.csv\"\n",
    "\n",
    "## Normalized neuropsych scores\n",
    "neuropsy_normed_dir = f\"{tabular_dir}/assessments/neuropsych_normed/\"\n",
    "neuropsy_scores_normed_file = f\"{tabular_dir}/assessments/neuropsych_normed.csv\"  # only a subset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_and_replace_df(df, filters_dict, rename_dict):\n",
    "    \"\"\" Subset rows and replace columns values in a dataframe\n",
    "    \"\"\"\n",
    "    for col, val_list in filters_dict.items():\n",
    "        df = df[df[col].isin(val_list)].copy()\n",
    "\n",
    "    for col, val_list in rename_dict.items():\n",
    "        df[col] = df[col].replace(val_list).copy()\n",
    "\n",
    "    return df\n",
    "\n",
    "def cheanup_col_names(df, index_cols, trailing_chars=[\":\"], trailing_spaces=True):\n",
    "    old_cols = list(df.columns.drop(index_cols) )\n",
    "    df_cols = df.columns.drop(index_cols)\n",
    "    if trailing_spaces:        \n",
    "        column_trimmed_dict = {col: col.strip() for col in df_cols}\n",
    "        df_cols = column_trimmed_dict.values()\n",
    "        df = df.rename(columns=column_trimmed_dict)\n",
    "\n",
    "    if len(trailing_chars) > 0:        \n",
    "        renamed_cols = []\n",
    "        for col in df_cols:            \n",
    "            for char in trailing_chars:                \n",
    "                if char == col[-1]:\n",
    "                    renamed_col = col.replace(char,\"\")\n",
    "                    renamed_cols.append(renamed_col)\n",
    "                    break\n",
    "                else:\n",
    "                    renamed_cols.append(col)\n",
    "        column_trimmed_dict = dict(zip(df_cols, renamed_cols))\n",
    "        df = df.rename(columns=column_trimmed_dict)\n",
    "    \n",
    "\n",
    "    new_cols = list(df.columns.drop(index_cols))\n",
    "    return df, old_cols, new_cols\n",
    "    \n",
    "def get_group_table_stats(df, cat_cols, score_cols, groupby_col=\"redcap_event_name\"):\n",
    "    \"\"\" Get table stats for groups. Does not stratify by group! \n",
    "    \"\"\"\n",
    "    n_cat_cols = len(cat_cols)\n",
    "    n_score_cols = len(score_cols)\n",
    "    print(f\"Counting {n_cat_cols} and averaging {n_score_cols}\")\n",
    "\n",
    "    # table_df = df[groupby_col].value_counts().reset_index()\n",
    "    table_df = df.groupby([groupby_col])[\"participant_id\"].count()\n",
    "    print(\"Starting cat cols\")\n",
    "    for col in cat_cols:\n",
    "        # print(f\"col: {col}\")\n",
    "        cat_count_df = df.groupby([groupby_col])[col].value_counts().unstack().reset_index()\n",
    "        table_df = pd.merge(table_df, cat_count_df, on=groupby_col, how=\"left\")\n",
    "\n",
    "    print(\"Starting score cols\")\n",
    "    for col in score_cols:\n",
    "        # print(f\"col: {col}\")\n",
    "        score_count = df.groupby([groupby_col])[col].count()\n",
    "        score_mean_df = df.groupby([groupby_col])[col].mean().round(1)\n",
    "        score_std_df = df.groupby([groupby_col])[col].std().round(1)\n",
    "        score_min_df = df.groupby([groupby_col])[col].min().round(2)\n",
    "        score_max_df = df.groupby([groupby_col])[col].max().round(2)\n",
    "        score_mean_std_df = \"(N=\" + score_count.astype(str) + \") \" + score_mean_df.astype(str) + \" (\" + score_std_df.astype(str) + \")\" + \" [\"  \\\n",
    "        + score_min_df.astype(str) + \", \" + score_max_df.astype(str) + \"]\"\n",
    "        score_mean_std_df = score_mean_std_df.reset_index()\n",
    "        # score_mean_std_df[\"non-null-count\"] = score_count\n",
    "        table_df = pd.merge(table_df, score_mean_std_df, on=groupby_col, how=\"left\")\n",
    "    \n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_df = pd.read_csv(manifest_file)\n",
    "demo_df = pd.read_csv(demographics_file)\n",
    "mri_df = pd.read_csv(mri_session_date_file)\n",
    "hy_df = pd.read_csv(hy_file)\n",
    "updrs_df = pd.read_csv(updrs_file)\n",
    "moca_df = pd.read_csv(moca_file)\n",
    "dx_df = pd.read_csv(dx_file)\n",
    "neuropsy_df = pd.read_csv(neuropsy_scores_file)\n",
    "neuropsy_normed_df = pd.read_csv(neuropsy_scores_normed_file)\n",
    "\n",
    "dx_df = dx_df[['participant_id', 'redcap_event_name','diagnosis_group_for_analysis']].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QPN paper tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper subset filters\n",
    "cohort_inclusion_list = [\"QPN\"]\n",
    "# group_inclusion_list = [\"Healthy control/Contrôle\", \"PD   (Parkinson's Disease)/Maladie de Parkinson\"]\n",
    "dx_inclusion_list = [\"PD\", \"control\"]\n",
    "visits_inclusion_list = [\"Baseline (Arm 1: C-OPN)\", \"legacy-updrs3\", \"legacy-moca\"]\n",
    "session_inclusion_list = [\"ses-01\"]\n",
    "\n",
    "participant_inclusion_criteria = {\n",
    "    \"redcap_event_name\" : visits_inclusion_list, \n",
    "    \"recruitment_cohort\": cohort_inclusion_list,\n",
    "    \"diagnosis_group_for_analysis\": dx_inclusion_list,\n",
    "    \"session\": session_inclusion_list\n",
    "    }\n",
    "\n",
    "# QPN_groups = {\"Healthy control/Contrôle\": \"control\", \"PD   (Parkinson's Disease)/Maladie de Parkinson\": \"PD\", np.NaN:\"Unknown\"}\n",
    "QPN_sexes = {\"Female/Féminin\": \"Female\", \"Male/Masculin\":\"Male\"}\n",
    "\n",
    "col_val_replacement_criteria = {\n",
    "    # \"enrollment_group\": QPN_groups,\n",
    "    \"sex\": QPN_sexes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df = pd.merge(manifest_df, demo_df, on=\"participant_id\", how=\"left\")\n",
    "# paper_df = pd.merge(paper_df, dx_df, on=[\"participant_id\",\"redcap_event_name\"], how=\"left\")\n",
    "\n",
    "n_tabular_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants: {n_tabular_participants}\")\n",
    "\n",
    "# Filter and replace values\n",
    "paper_df = subset_and_replace_df(paper_df, participant_inclusion_criteria, col_val_replacement_criteria)\n",
    "n_paper_participants = paper_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants after event and group filter: {n_paper_participants}\")\n",
    "\n",
    "session_counts = paper_df[\"session\"].value_counts()\n",
    "print(f\"session_counts: {session_counts}\")\n",
    "\n",
    "paper_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo table\n",
    "- Add MRI age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mri_age column\n",
    "paper_mri_df = pd.merge(paper_df, mri_df[[\"participant_id\", \"redcap_event_name\", \"MRI_age\"]], on=[\"participant_id\", \"redcap_event_name\"], how=\"left\")\n",
    "\n",
    "n_tabular_participants = paper_mri_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants: {n_tabular_participants}\")\n",
    "\n",
    "# Filter and replace values\n",
    "paper_mri_df = subset_and_replace_df(paper_mri_df, participant_inclusion_criteria, col_val_replacement_criteria)\n",
    "n_paper_participants = paper_mri_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants after event and group filter: {n_paper_participants}\")\n",
    "\n",
    "redcap_events = paper_mri_df[\"redcap_event_name\"].unique()\n",
    "print(f\"redcap events: {redcap_events}\")\n",
    "\n",
    "paper_mri_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts\n",
    "cat_cols = [\"sex\"]\n",
    "score_cols = [\"MRI_age\"] #education_years\n",
    "\n",
    "for dx in dx_inclusion_list:\n",
    "    print(f\"*** dx: {dx} ***\")\n",
    "    dx_group_df = paper_mri_df[paper_mri_df[\"diagnosis_group_for_analysis\"]==dx].copy()\n",
    "    table_df = get_group_table_stats(dx_group_df, cat_cols, score_cols)\n",
    "    print(\"-\"*10)\n",
    "    print(table_df)\n",
    "    print(\"-\"*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H&Y scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_Y_stage_dict = dict(zip(\n",
    "    [\n",
    "    '(2) Bilateral involvement without impairment of balance',\n",
    "    '(3) Bilateral disease: mild to moderate disability with impaired postural reflexes; physically independent; needs assistance to recover from pull test',\n",
    "    '(1) Unilateral involvement only, usually with minimal or no functional disability',\n",
    "    '(0) Asymptomatic',\n",
    "    '(4) Severely disabling disease; still able to walk or stand unassisted',\n",
    "    np.nan], \n",
    "    \n",
    "    ['2', '3', '1', '0', '4', \"N/A\"]\n",
    "))\n",
    "\n",
    "# hy_df[\"H_Y_stage\"] = hy_df['Hoehn and Yahr Stage'].replace(H_Y_stage_dict).copy()\n",
    "hy_df[\"H_Y_stage\"] = hy_df['Hoehn and Yahr Stage (derived)'].astype(int).astype(str).copy()\n",
    "hy_df = hy_df[hy_df[\"H_Y_stage\"]!=\"N/A\"]\n",
    "\n",
    "cat_cols = [\"H_Y_stage\"]\n",
    "score_cols = []\n",
    "\n",
    "hy_participants = hy_df[\"participant_id\"].nunique()\n",
    "hy_event_counts = hy_df[\"redcap_event_name\"].value_counts()\n",
    "\n",
    "print(f\"updrs_participants: {hy_participants}\")\n",
    "print(f\"updrs_event_counts: {hy_event_counts}\")\n",
    "\n",
    "paper_hy_df = pd.merge(dx_df.drop(columns=[\"redcap_event_name\"]), hy_df, on=[\"participant_id\"], how=\"right\")\n",
    "\n",
    "\n",
    "for dx_group in [\"PD\", \"control\"]:\n",
    "    print(f\"*** group: {dx_group} ***\")\n",
    "    dx_group_df = paper_hy_df[paper_hy_df[\"diagnosis_group_for_analysis\"]==dx_group].copy()\n",
    "    table_df = get_group_table_stats(dx_group_df, cat_cols, score_cols, groupby_col=\"diagnosis_group_for_analysis\")\n",
    "    print(\"-\"*10)\n",
    "    print(table_df)\n",
    "    print(\"-\"*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPDRS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updrs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updrs_participants = updrs_df[\"participant_id\"].nunique()\n",
    "updrs_event_counts = updrs_df[\"redcap_event_name\"].value_counts()\n",
    "\n",
    "print(f\"updrs_participants: {updrs_participants}\")\n",
    "print(f\"updrs_event_counts: {updrs_event_counts}\")\n",
    "\n",
    "paper_updrs_df = pd.merge(dx_df.drop(columns=[\"redcap_event_name\"]), updrs_df, on=[\"participant_id\"], how=\"right\")\n",
    "\n",
    "cat_cols = []\n",
    "score_cols = [\"Part III: Motor Examination (harmonized)\"]\n",
    "\n",
    "for dx in dx_inclusion_list:\n",
    "    print(f\"*** dx: {dx} ***\")\n",
    "    dx_group_df = paper_updrs_df[paper_updrs_df[\"diagnosis_group_for_analysis\"]==dx].copy()\n",
    "    table_df = get_group_table_stats(dx_group_df, cat_cols, score_cols, groupby_col=\"diagnosis_group_for_analysis\")\n",
    "    print(\"-\"*10)\n",
    "    print(table_df)\n",
    "    print(\"-\"*10)\n",
    "\n",
    "\n",
    "paper_updrs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MoCA score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moca_participants = moca_df[\"participant_id\"].nunique()\n",
    "moca_event_counts = moca_df[\"redcap_event_name\"].value_counts()\n",
    "\n",
    "print(f\"moca_participants: {moca_participants}\")\n",
    "print(f\"moca_event_counts: {moca_event_counts}\")\n",
    "\n",
    "moca_score_col = \"MoCA Total Score\"\n",
    "\n",
    "cog_subtype_col = \"cog_subgroup\"\n",
    "paper_moca_df = pd.merge(dx_df.drop(columns=[\"redcap_event_name\"]), moca_df, on=[\"participant_id\"], how=\"right\")\n",
    "paper_moca_df.loc[paper_moca_df[moca_score_col] >= 26, cog_subtype_col] = \"CN\" \n",
    "paper_moca_df.loc[(paper_moca_df[moca_score_col] >= 21) & (paper_moca_df[moca_score_col] < 26), cog_subtype_col] = \"MCI\"\n",
    "paper_moca_df.loc[paper_moca_df[moca_score_col] < 21, cog_subtype_col] = \"Dementia\"\n",
    "\n",
    "paper_moca_df = paper_moca_df.rename(columns={moca_score_col: \"moca_total\"}).copy()\n",
    "\n",
    "cat_cols = []\n",
    "score_cols = [\"moca_total\"]\n",
    "\n",
    "for dx in dx_inclusion_list:\n",
    "    print(f\"*** dx: {dx} ***\")\n",
    "    dx_group_df = paper_moca_df[paper_moca_df[\"diagnosis_group_for_analysis\"]==dx].copy()\n",
    "    table_df = get_group_table_stats(dx_group_df, cat_cols, score_cols, groupby_col=cog_subtype_col)\n",
    "    print(\"-\"*10)\n",
    "    print(table_df)\n",
    "    print(\"-\"*10)\n",
    "\n",
    "\n",
    "paper_moca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuropsy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsy_instruments = pd.read_csv(neuropsy_instruments_file)[\"instrument\"].tolist()\n",
    "print(f\"n_neuropsy_instruments: {len(neuropsy_instruments)}\")\n",
    "\n",
    "neuropsy_df = neuropsy_df[neuropsy_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "neuropsy_participants = neuropsy_df[\"participant_id\"].nunique()\n",
    "neuropsy_event_counts = neuropsy_df[\"redcap_event_name\"].value_counts()\n",
    "raw_score_cols = neuropsy_df.columns\n",
    "n_raw_cols = len(raw_score_cols)\n",
    "\n",
    "print(f\"neuropsy_participants: {neuropsy_participants}\")\n",
    "print(f\"neuropsy_event_counts: {neuropsy_event_counts}\")\n",
    "print(f\"neuropsy_cols: {n_raw_cols}\")\n",
    "\n",
    "## Normalize neuropsych scores (collated)\n",
    "neuropsy_demo_cols = [\"sex\", \"education\"]\n",
    "neuropsy_normed_participants = neuropsy_normed_df[\"participant_id\"].nunique()\n",
    "normed_cols = neuropsy_normed_df.columns[neuropsy_normed_df.columns.str.contains(\"ormed\")]\n",
    "# normed_cols = set(all_cols) - set(neuropsy_df.columns) - set(neuropsy_demo_cols)\n",
    "n_normed_cols = len(normed_cols)\n",
    "\n",
    "print(f\"neuropsy_normed_participants: {neuropsy_normed_participants}\")\n",
    "print(f\"neuropsy_normed_cols: {n_normed_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_col_type = \"raw\" # \"raw\" or \"normed\"\n",
    "\n",
    "if score_col_type == \"raw\":\n",
    "    paper_neuropsy_df = pd.merge(dx_df.drop(columns=[\"redcap_event_name\"]), neuropsy_df, on=[\"participant_id\"], how=\"right\")\n",
    "    score_cols = list(neuropsy_instruments)\n",
    "    paper_table_csv = \"./neuropsy_paper_table.csv\"\n",
    "\n",
    "elif score_col_type == \"normed\":\n",
    "    paper_neuropsy_df = pd.merge(dx_df.drop(columns=[\"redcap_event_name\"]), neuropsy_normed_df, on=[\"participant_id\"], how=\"right\")\n",
    "    score_cols = list(normed_cols)\n",
    "    paper_table_csv = \"./neuropsy_normed_paper_table.csv\"\n",
    "\n",
    "paper_neuropsy_df = paper_neuropsy_df[paper_neuropsy_df[\"diagnosis_group_for_analysis\"].isin(dx_inclusion_list)].copy()\n",
    "\n",
    "neuropsy_dx_counts = paper_neuropsy_df[\"diagnosis_group_for_analysis\"].value_counts()\n",
    "print(f\"neuropsy_dx_counts: {neuropsy_dx_counts}\")\n",
    "\n",
    "paper_neuropsy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = []\n",
    "table_df_all_groups = pd.DataFrame()\n",
    "for dx_group in dx_inclusion_list:\n",
    "    print(f\"*** dx_group: {dx_group} ***\")\n",
    "    dx_group_df = paper_neuropsy_df[(paper_neuropsy_df[\"diagnosis_group_for_analysis\"]==dx_group) ].copy()\n",
    "    table_df = get_group_table_stats(dx_group_df, cat_cols, score_cols, groupby_col=\"diagnosis_group_for_analysis\")\n",
    "    table_df[\"dx_group\"] = dx_group\n",
    "    print(\"-\"*10)\n",
    "    print(table_df)\n",
    "    print(\"-\"*10)\n",
    "\n",
    "    table_df_all_groups = pd.concat([table_df_all_groups, table_df], axis=0)\n",
    "\n",
    "table_df_all_groups.T.to_csv(paper_table_csv, index=True, sep=\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot pheno data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class my_colors(Enum):\n",
    "    CONTROL = \"#8d99ae\"\n",
    "    PD = \"#e63946\"\n",
    "    \n",
    "color_list = [my_colors.PD.value, my_colors.CONTROL.value,]\n",
    "palette = sns.color_palette(palette=color_list) #sns.husl_palette()\n",
    "\n",
    "monocrome_hot = [\"#370617\",\"#6a040f\",\"#9d0208\",\"#d00000\",\"#dc2f02\",\"#e85d04\",\"#f48c06\",\"#faa307\",\"#ffba08\"]\n",
    "monochrome_hot_palette = sns.color_palette(palette=monocrome_hot[::-2])[1:] #sns.husl_palette()\n",
    "\n",
    "sns.palplot(monochrome_hot_palette)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updrs_cols_dict = {\n",
    "    \"Hoehn and Yahr Stage\":'H_Y_stage',\n",
    "    'Part I: Non-Motor Aspects of Experiences of Daily Living (nM-EDL)':'Part I',\n",
    "    'Part II: Motor Aspects of Experiences of Daily Living (M-EDL)':'Part II',\n",
    "    'Part III: Motor Examination (harmonized)':'Part III',\n",
    "    'Part IV: Motor Complications':'Part IV',\n",
    "}\n",
    "\n",
    "H_Y_stage_dict = dict(zip(\n",
    "    [\n",
    "    '(2) Bilateral involvement without impairment of balance',\n",
    "    '(3) Bilateral disease: mild to moderate disability with impaired postural reflexes; physically independent; needs assistance to recover from pull test',\n",
    "    '(1) Unilateral involvement only, usually with minimal or no functional disability',\n",
    "    '(0) Asymptomatic',\n",
    "    '(4) Severely disabling disease; still able to walk or stand unassisted',\n",
    "    np.nan], \n",
    "    \n",
    "    ['2', '3', '1', '0', '4', \"N/A\"]\n",
    "))\n",
    "\n",
    "paper_updrs_df = paper_updrs_df.rename(columns=updrs_cols_dict)\n",
    "plot_df = pd.merge(paper_updrs_df, hy_df, on=[\"participant_id\",\"redcap_event_name\"], how=\"left\")\n",
    "# paper_df[\"H_Y_stage\"] = paper_df[\"H_Y_stage\"].replace(H_Y_stage_dict)\n",
    "# paper_df = paper_df[paper_df[\"H_Y_stage\"]!=\"N/A\"]\n",
    "\n",
    "# Melt for plotting\n",
    "plot_df = pd.melt(plot_df, id_vars=[\"participant_id\",\"redcap_event_name\",\"diagnosis_group_for_analysis\",\"H_Y_stage\"], \n",
    "                  value_vars=['Part I', 'Part II', 'Part III', 'Part IV'], \n",
    "                  var_name=\"UPDRS\", value_name=\"Score\")\n",
    "\n",
    "# plot_df = plot_df[plot_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "stage_order = ['1', '2', '3', '4']\n",
    "\n",
    "sns.set_theme(font_scale=3)\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    # g = sns.catplot(y=\"Score\",x=\"H_Y_stage\", order=stage_order,\n",
    "    #                 col=\"UPDRS\", col_wrap=2, \n",
    "    #                 kind=\"box\", palette=monochrome_hot_palette, \n",
    "    #                 data=plot_df, aspect=2, height=5, sharey=False, \n",
    "    #                 #boxprops=dict(linewidth=1.5)\n",
    "    #                 )\n",
    "\n",
    "    g = sns.FacetGrid(plot_df, col = \"UPDRS\", height = 8, aspect=1, sharex=True, sharey=False, col_wrap=4)\n",
    "    g = g.map_dataframe(pt.RainCloud, x = \"H_Y_stage\", y = \"Score\", order=stage_order,\n",
    "                        data = plot_df, palette=monochrome_hot_palette, #bw = 0.2, \n",
    "                        width_viol = 0.6, width_box = 0.3, box_manage_ticks = False,\n",
    "                        orient = \"v\", box_showfliers = False,\n",
    "                        point_size=10, point_alpha=0.3,\n",
    "                        box_linewidth = 3, cloud_alpha = 0, dodge = True)\n",
    "\n",
    "    g.set_titles(row_template = '{row_name}', col_template = '{col_name}')\n",
    "    g.set_xlabels(\"H&Y stage\")\n",
    "    g.set_ylabels(\"Score\")\n",
    "    g.despine(left=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_moca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = paper_moca_df.copy()\n",
    "plot_df = plot_df.rename(columns={\"diagnosis_group_for_analysis\":\"Dx\"})\n",
    "\n",
    "hue_order = [\"CN\", \"MCI\", \"Dementia\"]\n",
    "sns.set_theme(font_scale=2)\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(y=\"moca_total\",col=\"Dx\", x=cog_subtype_col, order=hue_order,\n",
    "                    kind=\"box\", palette=monochrome_hot_palette, \n",
    "                    data=plot_df, aspect=2, height=5, sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlsc612",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
