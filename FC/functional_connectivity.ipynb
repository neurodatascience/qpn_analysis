{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and plotting of structural networks from Tractflow output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_network_label(node, networks):\n",
    "    '''\n",
    "    find the network that appears the node's name\n",
    "    node is a string containing a node's name\n",
    "    networks is a list of networks names\n",
    "    '''\n",
    "    for network in networks:\n",
    "        if network in node:\n",
    "            return network\n",
    "    return None\n",
    "\n",
    "def segment_FC(FC, nodes, networks):\n",
    "    '''\n",
    "    average FC values over each large network in\n",
    "    networks\n",
    "    the output FC matrix will be in the same order as \n",
    "    networks\n",
    "    '''\n",
    "    segmented = np.zeros((len(networks), len(networks)))\n",
    "    counts = np.zeros((len(networks), len(networks)))\n",
    "    for i, node_i in enumerate(nodes):\n",
    "        network_i = networks.index(find_network_label(node_i, networks))\n",
    "        for j, node_j in enumerate(nodes):\n",
    "            network_j = networks.index(find_network_label(node_j, networks))\n",
    "            segmented[network_i, network_j] += FC[i, j]\n",
    "            counts[network_i, network_j] += 1\n",
    "    return np.divide(segmented, counts, out=np.zeros_like(segmented), where=counts!=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"qpn\"\n",
    "current_release = \"Oct_2024\" #\"Jan_2024\"\n",
    "fmriprep_version = \"v23.1.3\"\n",
    "session = \"ses-01\"\n",
    "\n",
    "dataset_dir = f\"/home/nikhil/projects/Parkinsons/{dataset}/\"\n",
    "release_dir = f\"{dataset_dir}/releases/{current_release}\"\n",
    "tabular_dir = f\"{release_dir}/tabular/\"\n",
    "\n",
    "derivatives_dir = f\"{dataset_dir}/derivatives/\"\n",
    "proc_dir = f\"{release_dir}/proc/\"\n",
    "\n",
    "# Current nipoppy manifest\n",
    "manifest_csv = f\"{release_dir}/manifest.csv\"\n",
    "\n",
    "# demographics\n",
    "demographics_csv = f\"{tabular_dir}/demographics.csv\"\n",
    "\n",
    "# Dx\n",
    "dx_csv = f\"{tabular_dir}/assessments/diagnosis.csv\"\n",
    "\n",
    "# fmriprep extractions\n",
    "fmriprep_extract_dir = f\"{derivatives_dir}/fmriprep/{fmriprep_version}/IDP/FC/output/\"\n",
    "\n",
    "# network defs\n",
    "tractoflow_dir = f\"{derivatives_dir}/tractoflow/v1.5.0/\"\n",
    "network_def_dir = f\"{tractoflow_dir}/networks/\"\n",
    "\n",
    "# Figures\n",
    "figs_dir = f\"{dataset_dir}/results/{session}/func/figs/\"\n",
    "Path(f\"{figs_dir}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_df = pd.read_csv(dx_csv)\n",
    "dx_df = dx_df[dx_df[\"redcap_event_name\"] == \"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "control_participants = dx_df[dx_df[\"diagnosis_group_for_analysis\"] == \"control\"][\"participant_id\"].unique()\n",
    "PD_participants = dx_df[dx_df[\"diagnosis_group_for_analysis\"] == \"PD\"][\"participant_id\"].unique()\n",
    "\n",
    "all_participants = list(control_participants) + list(PD_participants)\n",
    "\n",
    "print(f\"PD + control: {len(all_participants)}\")\n",
    "print(f\"Control: {len(control_participants)}\")\n",
    "print(f\"PD: {len(PD_participants)}\")\n",
    "\n",
    "dx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network regions\n",
    "space = \"MNI152NLin2009cAsym_res-2\"\n",
    "parcels = 100\n",
    "atlas = \"Schaefer2018\"\n",
    "desc = f\"{parcels}Parcels7Networks\"\n",
    "\n",
    "network_regions = f\"{network_def_dir}/atlas-{atlas}_desc-{desc}_dseg.tsv\"\n",
    "\n",
    "network_regions_df = pd.read_csv(network_regions, sep=\"\\t\")\n",
    "print(f\"network_regions_df.shape: {network_regions_df.shape}\")\n",
    "network_regions_df[[\"n_regions\", \"hemi\", \"network\", \"network_index\"]] = network_regions_df[\"name\"].str.split(\"_\",n=3,expand=True)\n",
    "network_regions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = \"ses-01\"\n",
    "metric = 'correlation' # correlation , covariance , precision \n",
    "YEO_networks = ['Vis', 'SomMot', 'DorsAttn', 'SalVentAttn', 'Limbic', 'Cont','Default']\n",
    "\n",
    "# participant_id = \"sub-PD00020\"\n",
    "PD_network_df_list = []\n",
    "HC_network_df_list = []\n",
    "missing_participants = []\n",
    "for participant_id in all_participants:\n",
    "    bids_id = f\"sub-{participant_id}\"\n",
    "    participant_FC_dir = f\"{fmriprep_extract_dir}/sub-{participant_id}/{session}/\"\n",
    "    participant_FC_npy = f\"{participant_FC_dir}/sub-{participant_id}_{session}_task-rest_space-{space}_FC_schaefer_{parcels}.npy\"\n",
    "\n",
    "    try:\n",
    "        FC = np.load(participant_FC_npy, allow_pickle=True).item()\n",
    "        roi_labels = FC['roi_labels']\n",
    "        roi_labels = [str(label) for label in roi_labels]\n",
    "        roi_labels = [label[label.find('Networks')+9:-3] for label in roi_labels]\n",
    "        segmented_FC = segment_FC(FC[metric], nodes=roi_labels, networks=YEO_networks)\n",
    "        FC_connectome = FC[metric]\n",
    "        # network_df = pd.DataFrame(FC_connectome, columns=roi_labels, index=roi_labels)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        missing_participants.append(participant_id)\n",
    "        print(f\"File not found: {participant_FC_npy}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    if participant_id in PD_participants:\n",
    "        PD_network_df_list.append(FC_connectome)\n",
    "    elif participant_id in control_participants:\n",
    "        HC_network_df_list.append(FC_connectome)\n",
    "    else:\n",
    "        print(f\"Participant {participant_id} not in PD or HC group\")\n",
    "\n",
    "n_available_PD = len(PD_network_df_list)\n",
    "n_available_HC = len(HC_network_df_list)\n",
    "print(f\"n available PD: {n_available_PD}, n available HC: {n_available_HC}\")\n",
    "print(f\"n missing participants: {len(missing_participants)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_participants_df = pd.DataFrame(missing_participants, columns=[\"participant_id\"])\n",
    "missing_participants_df.to_csv(f\"{proc_dir}/hpc_job_list_fmriprep_ses-01_resubmit.txt\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate and thrshold group networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_network = \"None\" #\"binarize\" #\"clip\" # for visualization purpose only\n",
    "\n",
    "threshold_dict = { \n",
    "    \"100Parcels7Networks\" : {\n",
    "        \"binarize\": 100,\n",
    "        \"lower_bound\": 100,\n",
    "        \"upper_bound\": 4000\n",
    "    },\n",
    "    \"1000Parcels7Networks\" : {\n",
    "        \"binarize\": 10,\n",
    "        \"lower_bound\": 2,\n",
    "        \"upper_bound\": 50\n",
    "    }\n",
    "}\n",
    "\n",
    "PD_network_df = np.stack(PD_network_df_list,axis=2).mean(axis=2)\n",
    "HC_network_df = np.stack(HC_network_df_list,axis=2).mean(axis=2)\n",
    "\n",
    "# sanity checks\n",
    "PD_avg_connectivity = PD_network_df.mean().round(3)\n",
    "HC_avg_connectivity = HC_network_df.mean().round(3)\n",
    "print(\"-\"*50)\n",
    "print(f\"n_PD: {n_available_PD}, PD_avg_connectivity: {PD_avg_connectivity}\")\n",
    "print(f\"n_HC: {n_available_HC}, HC_avg_connectivity: {HC_avg_connectivity}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "if threshold_network == \"binarize\":\n",
    "    print(\"Binarizing\")\n",
    "    thrshold = threshold_dict[desc][\"binarize\"]\n",
    "    PD_network_df = (PD_network_df > thrshold).astype(int)\n",
    "    HC_network_df = (HC_network_df > thrshold).astype(int)\n",
    "\n",
    "elif threshold_network == \"remove_outliers\":\n",
    "    print(\"Removing outliers\")\n",
    "    lower_bound = threshold_dict[desc][\"lower_bound\"]\n",
    "    upper_bound = threshold_dict[desc][\"upper_bound\"]\n",
    "    PD_network_df[(PD_network_df < lower_bound)] = 0\n",
    "    PD_network_df[(PD_network_df > upper_bound)] = upper_bound\n",
    "    HC_network_df[(HC_network_df < lower_bound)] = 0\n",
    "    HC_network_df[(HC_network_df > upper_bound)] = upper_bound\n",
    "else:\n",
    "    print(\"No thresholding applied\")\n",
    "\n",
    "# sanity checks\n",
    "PD_avg_connectivity = PD_network_df.mean().round(3)\n",
    "HC_avg_connectivity = HC_network_df.mean().round(3)\n",
    "print(\"-\"*50)\n",
    "print(f\"PD_avg_connectivity: {PD_avg_connectivity}\")\n",
    "print(f\"HC_avg_connectivity: {HC_avg_connectivity}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"PD_network_df.shape: {PD_network_df.shape}\")\n",
    "print(f\"HC_network_df.shape: {HC_network_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "\n",
    "n_color_bins = 10\n",
    "max_color = '#134074'\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('', ['white', max_color], n_color_bins)\n",
    "\n",
    "row_colors = network_regions_df[\"color\"]\n",
    "\n",
    "legend_TN = [mpatches.Patch(color=c, label=l) for c,l in network_regions_df[['color','network']].drop_duplicates(\"network\").values]\n",
    "midline_idx = PD_network_df.shape[0]//2\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    sns.set_context(\"paper\")\n",
    "    fig, axes = plt.subplots(nrows=1,ncols=2, figsize=(15, 7))\n",
    "    cbar_ax = fig.add_axes([.905, .2, .01, .6])\n",
    "\n",
    "    # -------------------------------------------------------------------------------------#\n",
    "    # PD\n",
    "    # -------------------------------------------------------------------------------------#\n",
    "    plot_df = PD_network_df.copy()\n",
    "    ax = axes[0]\n",
    "    g = sns.heatmap(plot_df, square=False, xticklabels=False, yticklabels=False, cmap=cmap, ax=ax, cbar=False) #cbar_kws={\"shrink\": .5}\n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=0)\n",
    "    # ax.set_title(f\"PD Network (n={n_available_PD})\",fontsize=15)\n",
    "    ax.set_title(f\"group: PD\",fontsize=15)\n",
    "    ax.axhline(y=midline_idx, color='k', linestyle='--')\n",
    "    ax.axvline(x=midline_idx, color='k', linestyle='--')\n",
    "   \n",
    "    for i, color in enumerate(row_colors):\n",
    "        g.add_patch(plt.Rectangle(xy=(-0.07, i), width=0.03, height=1, color=color, lw=0,\n",
    "                                transform=g.get_yaxis_transform(), clip_on=False))\n",
    "\n",
    "    # -------------------------------------------------------------------------------------#\n",
    "    # HC\n",
    "    # -------------------------------------------------------------------------------------#\n",
    "    plot_df = HC_network_df.copy()\n",
    "    ax = axes[1]\n",
    "    g = sns.heatmap(plot_df, square=False, xticklabels=False, yticklabels=False, cmap=cmap, ax=ax, \n",
    "                    cbar_kws= {'label': 'conmat-count'},cbar_ax=cbar_ax) #cbar_kws={\"shrink\": .5}\n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=0)\n",
    "    # ax.set_title(f\"HC Network (n={n_available_HC})\",fontsize=15)\n",
    "    ax.set_title(f\"group: control\",fontsize=15)\n",
    "    ax.axhline(y=midline_idx, color='k', linestyle='--')\n",
    "    ax.axvline(x=midline_idx, color='k', linestyle='--')\n",
    "\n",
    "    for i, color in enumerate(row_colors):\n",
    "        g.add_patch(plt.Rectangle(xy=(-0.07, i), width=0.03, height=1, color=color, lw=0,\n",
    "                                transform=g.get_yaxis_transform(), clip_on=False))\n",
    "    \n",
    "l2=g.legend(loc='center left',bbox_to_anchor=(-0.8,1.1),ncol=7, handles=legend_TN,frameon=True) #(1.01,0.9)\n",
    "l2.set_title(title='network',prop={'size':10})\n",
    "# plt.tight_layout()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(f\"{figs_dir}/{atlas}_{desc}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read graph properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_prop_pkl = f\"{release_dir}/derivatives/fmriprep/v23.1.3/IDP/FC/results//graph_prop_results.pkl\"\n",
    "\n",
    "graph_prop_dict = pd.read_pickle(graph_prop_pkl)\n",
    "\n",
    "print(graph_prop_dict.keys())\n",
    "\n",
    "graph_prop_df = pd.DataFrame()\n",
    "for key in graph_prop_dict.keys():\n",
    "    print(f\"{key}: {len(graph_prop_dict[key])}\")\n",
    "\n",
    "    _df = pd.DataFrame(graph_prop_dict[key])\n",
    "    _df[\"metric\"] = key\n",
    "    graph_prop_df = pd.concat([graph_prop_df, _df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class my_colors(Enum):\n",
    "    CONTROL = \"#8d99ae\"\n",
    "    PD = \"#e63946\"\n",
    "    \n",
    "color_list = [my_colors.PD.value, my_colors.CONTROL.value,]\n",
    "palette = sns.color_palette(palette=color_list) #sns.husl_palette()\n",
    "\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = graph_prop_df.copy()\n",
    "plot_df = plot_df.rename(columns={\"condition\": \"group\"})\n",
    "sns.set_theme(font_scale=2)\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(y=\"values\",x=\"group\", col=\"metric\", kind=\"box\",\n",
    "    palette=palette, data=plot_df, aspect=1, height=5, sharey=False)\n",
    "    g.set_xlabels(\"\")\n",
    "    # g.set_xticklabels(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipoppy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
