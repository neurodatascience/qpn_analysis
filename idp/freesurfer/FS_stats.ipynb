{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to analyze FS output\n",
    "\n",
    "1. DKT CT distributions \n",
    "2. ASEG vol distribution\n",
    "3. Surface plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "# from nilearn import datasets, surface, plotting\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"qpn\"\n",
    "current_release = \"Oct_2024\"\n",
    "FS_version = \"7.3.2\" #\"6.0.1\" #\"7.3.2\"\n",
    "session = \"ses-01\"\n",
    "\n",
    "dataset_dir = f\"/home/nikhil/projects/Parkinsons/{dataset}/\"\n",
    "release_dir = f\"{dataset_dir}/releases/{current_release}/\"\n",
    "tabular_dir = f\"{release_dir}/tabular/\"\n",
    "\n",
    "# Current nipoppy manifest\n",
    "manifest_csv = f\"{release_dir}/manifest.csv\"\n",
    "\n",
    "# demographics\n",
    "demographics_csv = f\"{tabular_dir}/demographics.csv\"\n",
    "\n",
    "# Dx\n",
    "dx_csv = f\"{tabular_dir}/assessments/diagnosis.csv\"\n",
    "\n",
    "# mri_info\n",
    "mri_sessions_csv = f\"{tabular_dir}/mri_info/mri_sessions.csv\"\n",
    "\n",
    "# imaging derivatives\n",
    "FS_dir = f\"{dataset_dir}/derivatives/freesurfer/v{FS_version}\"\n",
    "FS_DKT_dir = f\"{FS_dir}/IDP/{session}/\"\n",
    "DKT_csv = f\"{FS_DKT_dir}/dkt.csv\"\n",
    "ASEG_csv = f\"{FS_DKT_dir}/aseg.csv\"\n",
    "\n",
    "# aparc+aseg (nipoppy extractor)\n",
    "aparc_aseg_tsv = f\"{FS_DKT_dir}fs_stats-aseg-aparc_thickness.tsv\"\n",
    "\n",
    "# UKB encoding of FS fields (DKT + asg) and FS6 vs 7 ROI naming maps\n",
    "region_field_dir = \"/home/nikhil/projects/Parkinsons/region_field_ids/\"\n",
    "ukbb_dkt_ct_fields = f\"{region_field_dir}/FS_DKT_UKBB_Fields_ROI_map.csv\"\n",
    "ukbb_aseg_vol_fields = f\"{region_field_dir}/FS_ASEG_UKBB_Fields_ROI_map.csv\"\n",
    "\n",
    "# save dirs\n",
    "save_dir = f\"/home/nikhil/projects/Parkinsons/neuro_arch/analysis/IDP/{dataset}/{current_release}/agg_dfs/\"\n",
    "figs_dir = f\"{dataset_dir}/results/{session}/anat/figs/\"\n",
    "\n",
    "# Create dirs for results if they don't exist\n",
    "Path(f\"{save_dir}\").mkdir(parents=True, exist_ok=True)\n",
    "Path(f\"{figs_dir}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class my_colors(Enum):\n",
    "    CONTROL = \"#8d99ae\"\n",
    "    PD = \"#e63946\"\n",
    "    \n",
    "color_list = [my_colors.PD.value, my_colors.CONTROL.value,]\n",
    "palette = sns.color_palette(palette=color_list) #sns.husl_palette()\n",
    "\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_QC(df, check_cols, min_val, max_val, index_col=\"participant_id\"):\n",
    "    \"\"\"Checks for NaNs and out of range outliers \"\"\"\n",
    "    \n",
    "    if index_col in df.columns:\n",
    "        # check NaNs\n",
    "        nan_participants = df[df[check_cols].isna().any(axis=1)][index_col].values\n",
    "        n_nans = len(nan_participants)\n",
    "\n",
    "        # check range\n",
    "        outlier_participants = df[df[check_cols].apply(lambda x: (x < min_val) | (x > max_val)).any(axis=1)][index_col].values\n",
    "        n_outliers = len(outlier_participants)\n",
    "\n",
    "        print(f\"found {n_nans} NaNs and {n_outliers} outliers\")\n",
    "        return list(nan_participants), list(outlier_participants)\n",
    "    \n",
    "    else:\n",
    "        print(f\"Provide an index column\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_cols = [\"participant_id\", \"visit\", \"session\"]\n",
    "nipoppy_df = pd.read_csv(manifest_csv)\n",
    "nipoppy_df = nipoppy_df[manifest_cols] \n",
    "nipoppy_participants = nipoppy_df[\"participant_id\"].unique()\n",
    "n_nipoppy_participants = len(nipoppy_participants)\n",
    "print(f\"nipoppy participants: {n_nipoppy_participants}\")\n",
    "nipoppy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosis info\n",
    "- as confirmed later by the clinicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_df = pd.read_csv(dx_csv)\n",
    "dx_df = dx_df[dx_df[\"redcap_event_name\"] == \"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "control_participants = dx_df[dx_df[\"diagnosis_group_for_analysis\"] == \"control\"][\"participant_id\"].unique()\n",
    "PD_participants = dx_df[dx_df[\"diagnosis_group_for_analysis\"] == \"PD\"][\"participant_id\"].unique()\n",
    "\n",
    "all_participants = list(control_participants) + list(PD_participants)\n",
    "\n",
    "print(f\"PD + control: {len(all_participants)}\")\n",
    "print(f\"Control: {len(control_participants)}\")\n",
    "print(f\"PD: {len(PD_participants)}\")\n",
    "\n",
    "dx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UKB - DKT - ASEG fields and names\n",
    "- These change based on 1) ukbb names 2) FS6 and 3) FS7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DKT metadata\n",
    "DKT_fields_df = pd.read_csv(ukbb_dkt_ct_fields)\n",
    "DKT_fields_df[\"hemi_roi\"] = DKT_fields_df[\"hemi\"] + \".\" + DKT_fields_df[\"roi\"]\n",
    "# DKT_field_roi_dict = dict(zip(DKT_fields_df[\"Field ID\"].values.astype(\"str\"),DKT_fields_df[\"hemi_roi\"].values))\n",
    "\n",
    "CT_rois = list(DKT_fields_df[DKT_fields_df[\"hemi\"]==\"rh\"][\"roi\"])\n",
    "print(\"-\"*50)\n",
    "print(f\"Loading CT DKT map\")\n",
    "print(f\"n_CT_rois: {len(CT_rois)}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "lh_CT_rois = DKT_fields_df[DKT_fields_df[\"hemi\"]==\"lh\"][\"hemi_roi\"]\n",
    "rh_CT_rois = DKT_fields_df[DKT_fields_df[\"hemi\"]==\"rh\"][\"hemi_roi\"]\n",
    "\n",
    "# hemi specific dict with FS ROI names\n",
    "lh_CT_roi_dict = dict(zip(lh_CT_rois,CT_rois))\n",
    "rh_CT_roi_dict = dict(zip(rh_CT_rois,CT_rois))\n",
    "\n",
    "### ASEG metadata\n",
    "ASEG_fields_df = pd.read_csv(ukbb_aseg_vol_fields)\n",
    "left_hemi_suffixes = [\"Left-\",\"lh\",\"left-\"]\n",
    "right_hemi_suffixes = [\"Right-\",\"rh\",\"right-\"]\n",
    "\n",
    "roi_naming_version = FS_version.split(\".\",1)[0]\n",
    "print(f\"Loading vol ASEG map\")\n",
    "print(f\"**roi_naming_version: {roi_naming_version}**\")\n",
    "\n",
    "roi_col = f\"FS{roi_naming_version}_roi\"\n",
    "hemi_col = f\"FS{roi_naming_version}_hemi\"\n",
    "\n",
    "vol_ROIs = ASEG_fields_df[roi_col].values\n",
    "print(f\"n_vol_ROIs: {len(vol_ROIs)}\")\n",
    "vol_hemis = ASEG_fields_df[hemi_col].values\n",
    "vol_hemi_counts = ASEG_fields_df[hemi_col].value_counts()\n",
    "print(f\"n_rois per hemi: {vol_hemi_counts}\")\n",
    "\n",
    "lh_vol_rois = list(ASEG_fields_df[ASEG_fields_df[hemi_col].isin(left_hemi_suffixes)][roi_col].values)\n",
    "rh_vol_rois = list(ASEG_fields_df[ASEG_fields_df[hemi_col].isin(right_hemi_suffixes)][roi_col].values)\n",
    "global_vol_rois = list(ASEG_fields_df[ASEG_fields_df[hemi_col].isna()][roi_col].dropna().values)\n",
    "\n",
    "\n",
    "print(f\"n_lh_ASEG_rois: {len(lh_vol_rois)}\")\n",
    "print(f\"n_rh_ASEG_rois: {len(rh_vol_rois)}\")\n",
    "print(f\"n_global_ASEG_rois: {len(global_vol_rois)}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "ASEG_fields_df[hemi_col] = ASEG_fields_df[hemi_col].fillna(\"\")\n",
    "ASEG_fields_df[\"hemi_roi\"] = ASEG_fields_df[hemi_col] + ASEG_fields_df[roi_col] # delimiter is part of the hemi col is present\n",
    "lh_hemi_ASEG_rois = ASEG_fields_df[ASEG_fields_df[hemi_col].isin(left_hemi_suffixes)][\"hemi_roi\"]\n",
    "rh_hemi_ASEG_rois = ASEG_fields_df[ASEG_fields_df[hemi_col].isin(right_hemi_suffixes)][\"hemi_roi\"]\n",
    "\n",
    "lh_hemi_ASEG_roi_dict = dict(zip(lh_hemi_ASEG_rois,lh_vol_rois))\n",
    "rh_hemi_ASEG_roi_dict = dict(zip(rh_hemi_ASEG_rois,rh_vol_rois))\n",
    "\n",
    "ASEG_fields_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read DKT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_DKT_df = pd.read_csv(DKT_csv)\n",
    "CT_DKT_df[\"participant_id\"] = CT_DKT_df[\"participant_id\"].str.split(\"-\", expand=True)[1]\n",
    "\n",
    "FS_participants = list(CT_DKT_df[\"participant_id\"].unique())\n",
    "print(f\"n_FS_participants: {len(FS_participants)}\")\n",
    "\n",
    "# Check ROI names \n",
    "expected_cols = set(DKT_fields_df[\"hemi_roi\"].unique())\n",
    "data_cols = set(CT_DKT_df.columns)\n",
    "if len(expected_cols - data_cols) == 0:\n",
    "    print(\"all expected CT DKT ROI names are in the dataframe\")\n",
    "else:\n",
    "    extra_schema_cols = data_cols - expected_cols\n",
    "    print(f\"missing ROI names in the dataframe: {extra_schema_cols}\")\n",
    "\n",
    "unknown_CT_DKT_cols = set(CT_DKT_df.columns) - set(DKT_fields_df[\"hemi_roi\"].values) - set([\"participant_id\"])\n",
    "if len(unknown_CT_DKT_cols) > 0:\n",
    "    print(f\"found extra columns in CT DKT: {unknown_CT_DKT_cols}, dropping extra columns...\")\n",
    "    CT_DKT_df = CT_DKT_df.drop(columns=unknown_CT_DKT_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_DKT_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read aparc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_aparc_df = pd.read_csv(aparc_aseg_tsv, sep=\"\\t\")\n",
    "\n",
    "ct_cols = [col for col in CT_aparc_df.columns if \"thickness\" in col]\n",
    "\n",
    "# remove thickness suffix\n",
    "ct_cols_rename = [col.removesuffix(\"_thickness\") for col in ct_cols]\n",
    "\n",
    "# replace \"_\" with \".\"\n",
    "ct_cols_rename = [col.replace(\"_\",\".\") for col in ct_cols_rename]\n",
    "\n",
    "col_rename_map_dict = dict(zip(ct_cols, ct_cols_rename))\n",
    "\n",
    "# rename columns\n",
    "CT_aparc_df = CT_aparc_df.rename(columns=col_rename_map_dict).drop(columns=[\"session_id\"])\n",
    "CT_aparc_df = CT_aparc_df[[\"participant_id\"] + ct_cols_rename]\n",
    "\n",
    "\n",
    "CT_aparc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelation = \"aparc\" # or \"aparc\"\n",
    "## Merge with demographics\n",
    "\n",
    "startification_col = \"diagnosis_group_for_analysis\"\n",
    "demo_cols = [\"participant_id\", startification_col]\n",
    "\n",
    "if parcelation == \"DKT\":\n",
    "    print(f\"using DKT parcelation\")\n",
    "    CT_demo_df = pd.merge(CT_DKT_df,dx_df[demo_cols],on=\"participant_id\",how=\"left\")\n",
    "else:\n",
    "    print(f\"using aparc parcelation\")\n",
    "    CT_demo_df = pd.merge(CT_aparc_df,dx_df[demo_cols],on=\"participant_id\",how=\"left\")\n",
    "\n",
    "participants_per_group = CT_demo_df.groupby([startification_col])[\"participant_id\"].nunique()\n",
    "print(f\"participants per group: {participants_per_group}\")\n",
    "\n",
    "CT_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split DKT data into left and right hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False\n",
    "\n",
    "lh_CT_demo_df = CT_demo_df[list(lh_CT_rois) + demo_cols].copy()\n",
    "lh_CT_demo_df[\"hemi\"] = \"lh\"\n",
    "rh_CT_demo_df = CT_demo_df[list(rh_CT_rois) + demo_cols].copy()\n",
    "rh_CT_demo_df[\"hemi\"] = \"rh\"\n",
    "\n",
    "lh_CT_demo_df = lh_CT_demo_df.rename(columns=lh_CT_roi_dict)\n",
    "rh_CT_demo_df = rh_CT_demo_df.rename(columns=rh_CT_roi_dict)\n",
    "\n",
    "\n",
    "n_roi = CT_demo_df\n",
    "print(f\"n_roi={len(lh_CT_rois) + len(rh_CT_rois)}\")\n",
    "\n",
    "CT_demo_df = pd.concat([lh_CT_demo_df,rh_CT_demo_df], axis=0)\n",
    "\n",
    "if save_results:\n",
    "    CT_demo_df.to_csv(f\"{save_dir}/CT_demo_df.csv\")\n",
    "    \n",
    "CT_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick QC before plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_cols = lh_CT_roi_dict.values()\n",
    "min_val = 0.1\n",
    "max_val = 10\n",
    "nan_participants, outlier_participants = quick_QC(CT_demo_df, check_cols, min_val, max_val, index_col=\"participant_id\")\n",
    "remove_participants = list(set(nan_participants + outlier_participants))\n",
    "\n",
    "print(f\"removing {len(remove_participants)} participants: {remove_participants}\")\n",
    "CT_demo_df = CT_demo_df[~CT_demo_df[\"participant_id\"].isin(remove_participants)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "\n",
    "plot_groups = [\"control\",\"PD\"]\n",
    "CT_demo_df = CT_demo_df[CT_demo_df[\"diagnosis_group_for_analysis\"].isin(plot_groups)]\n",
    "\n",
    "CT_demo_df_melt = CT_demo_df.melt(\n",
    "    id_vars=demo_cols + [\"hemi\"],\n",
    "    var_name=\"ROI\", \n",
    "    value_name=\"CTh\")\n",
    "\n",
    "plot_df = CT_demo_df_melt.copy()\n",
    "plot_df[\"ROI\"] = plot_df[\"ROI\"].astype(str)\n",
    "\n",
    "plot_df[\"group\"] = plot_df[\"diagnosis_group_for_analysis\"] # rename for plotting\n",
    "\n",
    "n_participants = plot_df[\"participant_id\"].nunique()\n",
    "print(f\"n_participants: {n_participants}\")\n",
    "participants_per_group = plot_df.groupby([startification_col])[\"participant_id\"].nunique()\n",
    "print(f\"participants_per_group: {participants_per_group}\")\n",
    "\n",
    "sns.set_theme(font_scale=2.5)\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(y=\"ROI\",x=\"CTh\", hue=\"group\", col=\"hemi\",kind=\"box\",palette=palette, data=plot_df, aspect=0.5, height=20)\n",
    "    # g.tick_params(axis='x', rotation=90, labelsize=14)\n",
    "\n",
    "if save_fig:\n",
    "    g.savefig(f\"{figs_dir}/CT_{parcelation}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save CT DKT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_agg_CT_df = False\n",
    "\n",
    "if save_agg_CT_df:\n",
    "    save_file = f\"{save_dir}/CT_demo_df.csv\"\n",
    "    print(f\"Saving CT_demo_df to {save_file}\")\n",
    "    CT_demo_df.to_csv(save_file, index=False)\n",
    "\n",
    "CT_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volumetric measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_ASEG_df = pd.read_csv(ASEG_csv)\n",
    "\n",
    "vol_ASEG_df[\"participant_id\"] = vol_ASEG_df[\"participant_id\"].str.split(\"-\", expand=True)[1]\n",
    "\n",
    "FS_participants = list(vol_ASEG_df[\"participant_id\"].unique())\n",
    "print(f\"n_FS_participants: {len(FS_participants)}\")\n",
    "\n",
    "# Check the FS version and corresponding ROI\n",
    "\n",
    "expected_cols = set(ASEG_fields_df[\"hemi_roi\"].dropna().unique())\n",
    "data_cols = set(vol_ASEG_df.columns)\n",
    "\n",
    "if len(expected_cols - data_cols) == 0:\n",
    "    print(\"all expected CT DKT ROI names are in the dataframe\")\n",
    "else:\n",
    "    extra_schema_cols = expected_cols - data_cols\n",
    "    print(f\"missing columns in vol ASEG dataframe: {extra_schema_cols}\")\n",
    "\n",
    "\n",
    "unknown_vol_ASEG_cols = data_cols - expected_cols - set([\"participant_id\"])\n",
    "if len(unknown_vol_ASEG_cols) > 0:\n",
    "    print(f\"found extra columns: {unknown_vol_ASEG_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge with demographics\n",
    "startification_col = \"diagnosis_group_for_analysis\"\n",
    "demo_cols = [\"participant_id\", startification_col]\n",
    "vol_ASEG_df = pd.merge(vol_ASEG_df,dx_df[demo_cols],on=\"participant_id\",how=\"left\")\n",
    "\n",
    "participants_per_group = vol_ASEG_df.groupby([startification_col])[\"participant_id\"].nunique()\n",
    "print(f\"participants per group: {participants_per_group}\")\n",
    "\n",
    "vol_ASEG_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split bilateral volumetric data into left and right hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False\n",
    "\n",
    "lh_vol_ASEG_df = vol_ASEG_df[list(lh_hemi_ASEG_rois) + demo_cols].copy()\n",
    "lh_vol_ASEG_df[\"hemi\"] = \"lh\"\n",
    "rh_vol_ASEG_df = vol_ASEG_df[list(rh_hemi_ASEG_rois) + demo_cols].copy()\n",
    "rh_vol_ASEG_df[\"hemi\"] = \"rh\"\n",
    "global_vol_ASEG_df = vol_ASEG_df[global_vol_rois + demo_cols].copy()\n",
    "global_vol_ASEG_df[\"hemi\"] = \"global\"\n",
    "\n",
    "lh_vol_ASEG_df = lh_vol_ASEG_df.rename(columns=lh_hemi_ASEG_roi_dict)\n",
    "rh_vol_ASEG_df = rh_vol_ASEG_df.rename(columns=rh_hemi_ASEG_roi_dict)\n",
    "# global_vol_ASEG_df = global_vol_ASEG_df.rename(columns=global_ASEG_roi_dict)\n",
    "\n",
    "bilateral_vol_ASEG_df = pd.concat([lh_vol_ASEG_df,rh_vol_ASEG_df], axis=0)\n",
    "\n",
    "if save_results:\n",
    "    bilateral_vol_ASEG_df.to_csv(f\"{save_dir}/bilateral_vol_ASEG_df.csv\")\n",
    "    global_vol_ASEG_df.to_csv(f\"{save_dir}/global_vol_ASEG_df.csv\")\n",
    "\n",
    "bilateral_vol_ASEG_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick QC before plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_cols = lh_hemi_ASEG_roi_dict.values()\n",
    "min_val = 0\n",
    "max_val = 3000000\n",
    "nan_participants, outlier_participants = quick_QC(bilateral_vol_ASEG_df, check_cols, min_val, max_val, index_col=\"participant_id\")\n",
    "remove_participants = list(set(nan_participants + outlier_participants))\n",
    "\n",
    "print(f\"Bilateral regions: removing {len(remove_participants)} participants\")\n",
    "bilateral_vol_ASEG_df = bilateral_vol_ASEG_df[~bilateral_vol_ASEG_df[\"participant_id\"].isin(remove_participants)]\n",
    "\n",
    "check_cols = global_vol_rois\n",
    "nan_participants, outlier_participants = quick_QC(global_vol_ASEG_df, check_cols, min_val, max_val, index_col=\"participant_id\")\n",
    "remove_participants = list(set(nan_participants + outlier_participants))\n",
    "\n",
    "print(f\"Global regions: removing {len(remove_participants)} participants\")\n",
    "global_vol_ASEG_df = global_vol_ASEG_df[~global_vol_ASEG_df[\"participant_id\"].isin(remove_participants)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ASEG\n",
    "- hemi \n",
    "- global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "\n",
    "# Rename global regions for brevity\n",
    "plot_renaming_dict = {\"Thalamus-Proper\":\"Thalamus\"} #FSv6 --> FSv7\n",
    "global_vol_ASEG_df = global_vol_ASEG_df.rename(columns=plot_renaming_dict)\n",
    "\n",
    "plot_groups = [\"control\",\"PD\"]\n",
    "bilateral_vol_ASEG_df = bilateral_vol_ASEG_df[bilateral_vol_ASEG_df[\"diagnosis_group_for_analysis\"].isin(plot_groups)]\n",
    "\n",
    "vol_ASEG_df_melt = bilateral_vol_ASEG_df.melt(\n",
    "    id_vars=demo_cols + [\"hemi\"],\n",
    "    var_name=\"ROI\", \n",
    "    value_name=\"volume\",\n",
    ")\n",
    "\n",
    "plot_df = vol_ASEG_df_melt.copy()\n",
    "plot_df[\"ROI\"] = plot_df[\"ROI\"].astype(str)\n",
    "hemi_roi_list = ['Pallidum', 'Thalamus', 'Putamen',  'Amygdala', 'Caudate', 'Hippocampus', 'Accumbens-area', \n",
    "                'Cerebellum-Cortex','Cerebellum-White-Matter','VentralDC', 'Lateral-Ventricle','Inf-Lat-Vent']\n",
    "\n",
    "n_participants = plot_df[\"participant_id\"].nunique()\n",
    "print(f\"n_participants: {n_participants}\")\n",
    "participants_per_group = plot_df.groupby([startification_col])[\"participant_id\"].nunique()\n",
    "print(f\"participants_per_group: {participants_per_group}\")\n",
    "\n",
    "plot_df[\"group\"] = plot_df[\"diagnosis_group_for_analysis\"] # rename for plotting\n",
    "\n",
    "sns.set_theme(font_scale=4)\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(y=\"volume\",x=\"hemi\", hue=\"group\", col=\"ROI\",kind=\"box\", col_wrap=6, col_order=hemi_roi_list,\n",
    "    palette=palette, data=plot_df, aspect=1, height=10, sharey=False)\n",
    "    # g.tick_params(axis='x', rotation=90, labelsize=14)\n",
    "\n",
    "if save_fig:\n",
    "    g.savefig(f\"{figs_dir}/ASEG_bilateral.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save hemi aseg vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_agg_aseg_df = False\n",
    "\n",
    "if save_agg_aseg_df:\n",
    "    save_file = f\"{save_dir}/bilateral_vol_ASEG_df.csv\"\n",
    "    print(f\"Saving aseg_DKT_df to {save_file}\")\n",
    "    bilateral_vol_ASEG_df.to_csv(save_file, index=False)\n",
    "\n",
    "bilateral_vol_ASEG_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "\n",
    "# Rename global regions for brevity\n",
    "plot_renaming_dict = {\"EstimatedTotalIntraCranialVol\":\"eTIV\"}\n",
    "global_vol_ASEG_df = global_vol_ASEG_df.rename(columns=plot_renaming_dict)\n",
    "\n",
    "plot_groups = [\"control\",\"PD\"]\n",
    "global_vol_ASEG_df = global_vol_ASEG_df[global_vol_ASEG_df[\"diagnosis_group_for_analysis\"].isin(plot_groups)]\n",
    "\n",
    "\n",
    "global_vol_ASEG_df_melt = global_vol_ASEG_df.melt(\n",
    "    id_vars=demo_cols + [\"hemi\"],\n",
    "    var_name=\"ROI\", \n",
    "    value_name=\"volume\",\n",
    ")\n",
    "\n",
    "plot_df = global_vol_ASEG_df_melt.copy()\n",
    "\n",
    "global_roi_list = [\"eTIV\", \"SupraTentorial\", \"TotalGray\", \"SubCortGray\", \n",
    "                    \"CSF\",\"Brain-Stem\",\"3rd-Ventricle\",\"4th-Ventricle\"]\n",
    "plot_df = plot_df[plot_df[\"ROI\"].isin(global_roi_list)]\n",
    "\n",
    "n_participants = plot_df[\"participant_id\"].nunique()\n",
    "print(f\"n_participants: {n_participants}\")\n",
    "participants_per_group = plot_df.groupby([startification_col])[\"participant_id\"].nunique()\n",
    "print(f\"participants_per_group: {participants_per_group}\")\n",
    "\n",
    "plot_df[\"group\"] = plot_df[\"diagnosis_group_for_analysis\"] # rename for plotting\n",
    "\n",
    "\n",
    "sns.set_theme(font_scale=4)\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(y=\"volume\",x=\"hemi\", hue=\"group\", col=\"ROI\",kind=\"box\", col_wrap=4, col_order=global_roi_list,\n",
    "    palette=palette, data=plot_df, aspect=1, height=10, sharey=False)\n",
    "    g.set_xlabels(\"\")\n",
    "    g.set_xticklabels(\"\")\n",
    "\n",
    "if save_fig:\n",
    "    g.savefig(f\"{figs_dir}/ASEG_global.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save global aseg vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_agg_aseg_df = False\n",
    "\n",
    "if save_agg_aseg_df:\n",
    "    save_file = f\"{save_dir}/global_vol_ASEG_df.csv\"\n",
    "    print(f\"Saving aseg_DKT_df to {save_file}\")\n",
    "    global_vol_ASEG_df.to_csv(save_file, index=False)\n",
    "\n",
    "global_vol_ASEG_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make enigma-plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enigmatoolbox.plotting import plot_subcortical, plot_cortical\n",
    "from enigmatoolbox.datasets import load_example_data\n",
    "from enigmatoolbox.utils.parcellation import parcel_to_surface\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enigma_rois = [\n",
    "    'Left-Lateral-Ventricle', 'Left-Thalamus', 'Left-Caudate', \n",
    "    'Left-Putamen', 'Left-Pallidum', 'Left-Hippocampus', 'Left-Amygdala', \n",
    "    'Left-Accumbens-area', 'Right-Lateral-Ventricle', 'Right-Thalamus', \n",
    "    'Right-Caudate', 'Right-Putamen', 'Right-Pallidum', 'Right-Hippocampus', \n",
    "    'Right-Amygdala', 'Right-Accumbens-area'\n",
    "]\n",
    "\n",
    "global_vol_roi  = 'EstimatedTotalIntraCranialVol'\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(f\"n_enigma_rois: {len(enigma_rois)}, global_vol_roi: {global_vol_roi}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# for plotting purposes\n",
    "enigma_order = [7, 6, 2, 5, 4, 3, 1, 0, 15, 14, 10, 13, 12, 11, 9, 8]\n",
    "\n",
    "demo_cols = [\"participant_id\", \"diagnosis_group_for_analysis\"]\n",
    "\n",
    "enigma_vol_df = vol_ASEG_df[demo_cols + enigma_rois + [global_vol_roi]]\n",
    "\n",
    "plot_groups = [\"control\",\"PD\"]\n",
    "enigma_vol_df = enigma_vol_df[enigma_vol_df[\"diagnosis_group_for_analysis\"].isin(plot_groups)]\n",
    "\n",
    "# Sanity checks\n",
    "enigma_vol_df_control = enigma_vol_df[enigma_vol_df[\"diagnosis_group_for_analysis\"] == \"control\"]\n",
    "enigma_vol_df_PD = enigma_vol_df[enigma_vol_df[\"diagnosis_group_for_analysis\"] == \"PD\"]\n",
    "\n",
    "PD_avg_vol = enigma_vol_df_PD[enigma_rois].mean().values[enigma_order]\n",
    "control_avg_vol = enigma_vol_df_control[enigma_rois].mean().values[enigma_order]\n",
    "\n",
    "print(f\"PD_avg_vol: {PD_avg_vol}\")\n",
    "print(f\"control_avg_vol: {control_avg_vol}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get demographics for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = pd.read_csv(demographics_csv)\n",
    "demo_df = demo_df[demo_df[\"redcap_event_name\"] == \"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "demo_cols = [\"participant_id\", \"sex\"]\n",
    "demo_df = demo_df[demo_cols]\n",
    "\n",
    "mri_sessions_df = pd.read_csv(mri_sessions_csv)\n",
    "mri_sessions_df = mri_sessions_df[mri_sessions_df[\"redcap_event_name\"] == \"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "\n",
    "demo_df = pd.merge(demo_df, mri_sessions_df, on=\"participant_id\", how=\"left\")\n",
    "\n",
    "demo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_enigma_vol_df = enigma_vol_df.copy()\n",
    "# normalized_enigma_vol_df[enigma_rois] = enigma_vol_df[enigma_rois].div(enigma_vol_df[global_vol_roi], axis=0) * 100 \n",
    "\n",
    "normalized_enigma_vol_df = pd.merge(normalized_enigma_vol_df, demo_df, on=\"participant_id\", how=\"left\")\n",
    "normalized_enigma_vol_df = normalized_enigma_vol_df.rename(columns={\"diagnosis_group_for_analysis\":\"group\", \"MRI_age\":\"age\"})\n",
    "\n",
    "save_dir = \"/home/nikhil/projects/Parkinsons/qpn//results/ses-01/anat/dfs/\"\n",
    "normalized_enigma_vol_df.to_csv(f\"{save_dir}/normalized_enigma_vol_df.csv\", index=False)\n",
    "normalized_enigma_vol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = normalized_enigma_vol_df.copy()\n",
    "\n",
    "betas = pd.DataFrame(index=['const', 'group', 'age', 'sex', 'ICV'], columns=enigma_rois)\n",
    "dvals = pd.DataFrame(index=['const', 'group', 'age', 'sex', 'ICV'], columns=enigma_rois)\n",
    "pvals = pd.DataFrame(index=['const', 'group', 'age', 'sex', 'ICV'], columns=enigma_rois)\n",
    "for roi in enigma_rois:\n",
    "    new_roi = roi.replace(\"-\",\"\")\n",
    "    # print(f\"running model for {roi}-->{new_roi}\")\n",
    "    stats_df = stats_df.rename(columns={roi:new_roi})\n",
    "    model = smf.ols(formula=f\"{new_roi} ~ age + C(group, Treatment(reference='control')) + C(sex) + EstimatedTotalIntraCranialVol\", data=stats_df).fit()\n",
    "    betas[roi] = model.params.values\n",
    "    dvals[roi] = model.params[1]/np.std(model.resid, ddof=1)\n",
    "    pvals[roi] = model.pvalues.values\n",
    "\n",
    "# reorder results based on enigma order of ROIs\n",
    "b = betas.loc['group'][enigma_order]\n",
    "d = dvals.loc['group'][enigma_order]\n",
    "p = multipletests(pvals.loc['group'], method='fdr_bh')[1][enigma_order]\n",
    "\n",
    "d_thresholded = d.where(p < 0.05, other=pd.NA)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_thresholded = False\n",
    "# visualize results\n",
    "min_color = -np.abs(d_thresholded).max().round(2)\n",
    "max_color = np.abs(d_thresholded).max().round(2)\n",
    "\n",
    "print(f\"min_color: {min_color}, max_color: {max_color}\")\n",
    "\n",
    "if use_thresholded:\n",
    "    print(\"using thresholded effect sizes\")\n",
    "    array_name = d_thresholded\n",
    "    save_file = f\"{figs_dir}/enigma_vols_thresholded_effect_size.png\"\n",
    "else:\n",
    "    print(\"using unthresholded effect sizes\")\n",
    "    array_name = d\n",
    "    save_file = f\"{figs_dir}/enigma_vols_unthresholded_effect_size.png\"\n",
    "\n",
    "print(f\"save_file: {save_file}\")\n",
    "plot_subcortical(array_name=array_name, size=(900, 250), color_bar='bottom', zoom=1.25, embed_nb=True, \n",
    "                    interactive=False, share='both', color_range=(min_color, max_color), \n",
    "                    nan_color=(255, 255, 255, 1), cmap=\"coolwarm\", transparent_bg=True,\n",
    "                    screenshot=True, filename=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot cortical thickness\n",
    "\n",
    "The example datasets from enigma toolbox donot load. However, we can look at the list and order of CT structures here:\n",
    "https://github.com/MICA-MNI/ENIGMA/blob/master/enigmatoolbox/datasets/summary_statistics/gge_case-controls_CortThick.csv\n",
    "\n",
    "This is same as the default list from aparc.stats summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_aparc_df = pd.read_csv(aparc_aseg_tsv, sep=\"\\t\").drop(columns=[\"lh_MeanThickness_thickness\",\"rh_MeanThickness_thickness\"])\n",
    "ct_cols = [col for col in CT_aparc_df.columns if \"thickness\" in col]\n",
    "ct_cols_rename = [col.removesuffix(\"_thickness\") for col in ct_cols]\n",
    "CT_aparc_df = CT_aparc_df.rename(columns=dict(zip(ct_cols, ct_cols_rename)))\n",
    "CT_aparc_df = CT_aparc_df[[\"participant_id\"] + ct_cols_rename]\n",
    "CT_aparc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge CT with demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = pd.read_csv(demographics_csv)\n",
    "demo_df = demo_df[demo_df[\"redcap_event_name\"] == \"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "demo_cols = [\"participant_id\", \"sex\"]\n",
    "demo_df = demo_df[demo_cols]\n",
    "\n",
    "mri_sessions_df = pd.read_csv(mri_sessions_csv)\n",
    "mri_sessions_df = mri_sessions_df[mri_sessions_df[\"redcap_event_name\"] == \"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "dx_df = pd.read_csv(dx_csv)\n",
    "dx_df = dx_df[dx_df[\"redcap_event_name\"] == \"Baseline (Arm 1: C-OPN)\"]\n",
    "\n",
    "dx_cols = [\"participant_id\", \"diagnosis_group_for_analysis\"]\n",
    "dx_df = dx_df[dx_cols]\n",
    "\n",
    "demo_df = pd.merge(demo_df, mri_sessions_df, on=\"participant_id\", how=\"left\")\n",
    "demo_df = pd.merge(demo_df, dx_df, on=\"participant_id\", how=\"left\")\n",
    "\n",
    "CT_aparc_demo_df = pd.merge(CT_aparc_df, demo_df, on=\"participant_id\", how=\"left\")\n",
    "\n",
    "CT_aparc_demo_df = CT_aparc_demo_df.rename(columns={\"diagnosis_group_for_analysis\":\"group\", \"MRI_age\":\"age\"})\n",
    "CT_aparc_demo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = CT_aparc_demo_df[CT_aparc_demo_df[\"group\"].isin([\"control\",\"PD\"])].copy()\n",
    "\n",
    "betas = pd.DataFrame(index=['const', 'group', 'age', 'sex'], columns=ct_cols_rename)\n",
    "dvals = pd.DataFrame(index=['const', 'group', 'age', 'sex'], columns=ct_cols_rename)\n",
    "pvals = pd.DataFrame(index=['const', 'group', 'age', 'sex'], columns=ct_cols_rename)\n",
    "for roi in ct_cols_rename:\n",
    "    new_roi = roi.replace(\"_\",\"\")\n",
    "    stats_df = stats_df.rename(columns={roi:new_roi})\n",
    "    model = smf.ols(formula=f\"{new_roi} ~ age + C(group, Treatment(reference='control')) + C(sex)\", data=stats_df).fit()\n",
    "    betas[roi] = model.params.values\n",
    "    dvals[roi] = model.params[1]/np.std(model.resid, ddof=1)\n",
    "    pvals[roi] = model.pvalues.values\n",
    "\n",
    "# reorder results based on enigma order of ROIs\n",
    "b = betas.loc['group']\n",
    "d = dvals.loc['group']\n",
    "p = multipletests(pvals.loc['group'], method='fdr_bh')[1]\n",
    "\n",
    "d_thresholded = d.where(p < 0.05, other=pd.NA)\n",
    "\n",
    "\n",
    "print(f\"max d: {d.max()}, (max, min) thresholded d: {d_thresholded.max()}, {d_thresholded.min()}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enigmatoolbox.plotting import plot_subcortical, plot_cortical\n",
    "from enigmatoolbox.utils.parcellation import parcel_to_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val = parcel_to_surface(d, 'aparc_fsa5')\n",
    "\n",
    "print(plot_val.shape)\n",
    "\n",
    "min_color = -np.abs(plot_val).max().round(2)\n",
    "max_color = np.abs(plot_val).max().round(2)\n",
    "\n",
    "save_file = f\"{figs_dir}/enigma_CT_effect_size.png\"\n",
    "print(f\"min_color: {min_color}, max_color: {max_color}\")\n",
    "print(f\"save_file: {save_file}\")\n",
    "plot_cortical(array_name=plot_val, surface_name=\"fsa5\", size=(900, 250), color_bar='bottom', zoom=1.25, embed_nb=True, \n",
    "                    interactive=True, share='both', color_range=(min_color, max_color), \n",
    "                    nan_color=(255, 255, 255, 1), cmap=\"coolwarm\", transparent_bg=True, \n",
    "                    screenshot=True, filename=save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "999c495fe9dc36b558f9181c52eb411f8d79bcfd8fb93141da57ede7d0ce5d9c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('green_compute')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
